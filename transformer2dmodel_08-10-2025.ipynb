{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":39911,"sourceType":"datasetVersion","datasetId":31296},{"sourceId":600823,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":448695,"modelId":465100}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n# %pip install git+https://github.com/huggingface/diffusers\n# %pip install peft==0.17\n%pip install -U neptune\n# %pip install -U \"huggingface_hub[cli]\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!huggingface-cli login --token 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 --add-to-git-credential","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/tirthadagr8/generated_image_ds.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport json # for reading annotations from json\nfrom tqdm.auto import tqdm\nimport random\nimport math\nfrom PIL import Image,ImageDraw\nimport tensorflow as tf\nfrom collections import Counter \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\nfrom torch.nn import functional as F\nfrom torchvision import transforms as T\nfrom torch import optim\nimport yaml\nimport argparse\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom sklearn.metrics import precision_score, recall_score,confusion_matrix,ConfusionMatrixDisplay\n\n# import h5py\n# !pip install torchsummary\n# from torchsummary import summary\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.datasets import ImageFolder\nfrom IPython.display import clear_output\nfrom transformers import CLIPTextModel, CLIPTokenizer\nfrom diffusers import PNDMScheduler\n# from transformers import Qwen2VLTextModel,AutoProcessor,Qwen3ForCausalLM\n# from diffusers import QwenImageTransformer2DModel\n# !pip install einops\n# import einops","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:08.902149Z","iopub.execute_input":"2025-10-07T15:46:08.902637Z","iopub.status.idle":"2025-10-07T15:46:18.686622Z","shell.execute_reply.started":"2025-10-07T15:46:08.902609Z","shell.execute_reply":"2025-10-07T15:46:18.685951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_encoder_path = \"google/t5-v1_1-base\" #Qwen/Qwen3-Embedding-0.6B #bert-base-uncased #openai/clip-vit-base-patch32\ntext_tokenizer_path = \"google/t5-v1_1-base\"\nvae_model=\"tirthadagr8/T2I_UNet\"\nmodel_max_length=128\nimg_size=(128,128)\nckpt_path = \"/kaggle/input/unet2d_500m/transformers/default/3/unet2d_500M.pt\"\nadapter_weights=\"dummy\"\nscheduler_path=\"tirthadagr8/T2I_UNet\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:18.687852Z","iopub.execute_input":"2025-10-07T15:46:18.688313Z","iopub.status.idle":"2025-10-07T15:46:18.692501Z","shell.execute_reply.started":"2025-10-07T15:46:18.688293Z","shell.execute_reply":"2025-10-07T15:46:18.691681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom collections import defaultdict\nfrom transformers import AutoTokenizer, AutoModel\n\n# feature_extractor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n# Load captions\ndf = pd.read_csv(\"/kaggle/working/generated_image_ds/generated_image_dataset/results.csv\", \n                 sep=\"|\", names=[\"image_name\", \"comment_number\", \"comment\"])\ndf = df.dropna(subset=['comment'])                 # Drop NaNs\ndf = df[df['comment'].str.strip() != \"\"]           # Drop empty strings\ndf = df.reset_index(drop=True)                    # Reset index\n\n# Clean up whitespace\ndf[\"comment\"] = df[\"comment\"].str.strip()\n\n# Group captions by image\ncaption_dict = defaultdict(list)\nfor _, row in df.iterrows():\n    if _==0:\n        continue\n    caption_dict[row[\"image_name\"]].append(row[\"comment\"])\n\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport random\nimport torchvision.transforms as T\n\nclass FlickrDataset(Dataset):\n    def __init__(self, image_dir, caption_dict, transform=None):\n        self.image_dir = image_dir\n        self.synthetic_dir = \"/kaggle/working/generated_image_ds/generated_image_dataset\"\n        self.caption_dict = caption_dict\n        self.image_names = list(caption_dict.keys())\n        self.transform = transform or self.default_transforms()\n\n    def default_transforms(self):\n        return T.Compose([\n            T.Resize(img_size),  # Adjust based on your model\n            T.ToTensor(),\n            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx]\n        if \"image_\" in image_name:\n            image_path = os.path.join(self.synthetic_dir, image_name)\n        else:\n            image_path = os.path.join(self.image_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n        except Exception as e:\n            print(f\"Error loading image {image_name}: {e}\")\n            return self.__getitem__((idx + 1) % len(self))  # Skip bad images\n\n        # Randomly pick one caption\n        caption = random.choice(self.caption_dict[image_name])\n        \n        return {\n            \"image\": image,\n            \"text\": caption,\n            \"image_name\": image_name\n        }\n\ndef collate_fn(batch, tokenizer, max_length=77):\n    images = torch.stack([item[\"image\"] for item in batch])\n    texts = [item[\"text\"] for item in batch]\n    # print('MaxLength:',max_length)\n    encoded = tokenizer(\n        texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=tokenizer.model_max_length,\n        return_tensors=\"pt\"\n    )\n    \n    return {\n        \"image\": images,\n        \"input_ids\": encoded[\"input_ids\"],\n        \"attention_mask\": encoded[\"attention_mask\"]\n    }\n\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer\n\n# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(text_tokenizer_path)\ntokenizer.model_max_length=model_max_length\n# Define dataset\nimage_dir = \"/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images\"\ndataset = FlickrDataset(image_dir=image_dir, caption_dict=caption_dict)\ndataloader = DataLoader(\n    dataset,\n    batch_size=8,\n    # shuffle=True,\n    num_workers=4,\n    collate_fn=lambda b: collate_fn(b, tokenizer=tokenizer),\n    drop_last=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:18.693278Z","iopub.execute_input":"2025-10-07T15:46:18.693482Z","iopub.status.idle":"2025-10-07T15:46:25.593351Z","shell.execute_reply.started":"2025-10-07T15:46:18.693466Z","shell.execute_reply":"2025-10-07T15:46:25.592740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torchvision import transforms as T\n# from transformers import CLIPTextModel, CLIPTokenizer\n# from torch.utils.data import DataLoader, Dataset\n# from datasets import load_dataset\n# from torch.utils.data import IterableDataset\n# from transformers import ViTImageProcessor\n# import time\n# import random\n# from requests.exceptions import ChunkedEncodingError, ConnectionError, HTTPError\n# from urllib3.exceptions import ProtocolError, IncompleteRead\n# from PIL import UnidentifiedImageError\n\n# # ============= LOADING 2M Dataset =============== #\n# base_url = \"https://huggingface.co/datasets/jackyhate/text-to-image-2M/resolve/main/data_512_2M/data_{i:06d}.tar\"\n# num_shards = 46  # Number of webdataset tar files\n# urls = [base_url.format(i=i) for i in range(num_shards)]\n# streaming_realdata = load_dataset(\"webdataset\", data_files={\"train\": urls}, split=\"train\", streaming=True)\n\n# # ============= LOADING 4M ANIME DATASET ========= #\n# base_url='https://huggingface.co/datasets/latentcat/animesfw/resolve/main/data/'\n# urls=['train-00120-of-00969-790dc2f13eccb695.parquet', 'train-00351-of-00969-1db0de9923468dd5.parquet', 'train-00825-of-00969-fb9c02fb3a97c3f5.parquet', 'train-00324-of-00969-65109d61f3e1e6cb.parquet', 'train-00485-of-00969-57158bbe5c9a48ab.parquet', 'train-00176-of-00969-53d9154cd8306643.parquet', 'train-00245-of-00969-5a0680a672e4d068.parquet', 'train-00735-of-00969-7038bcdb94a28d51.parquet', 'train-00866-of-00969-895ea2f9ea1b39b9.parquet', 'train-00095-of-00969-ebff49882cecae09.parquet', 'train-00130-of-00969-c59a32432431f28c.parquet', 'train-00648-of-00969-7abfb75aa053e576.parquet', 'train-00868-of-00969-4955728b1b722417.parquet', 'train-00202-of-00969-4fdc5d8fadff7529.parquet', 'train-00241-of-00969-5838f44b21a30f1e.parquet', 'train-00613-of-00969-2aa79a2b30d5f966.parquet', 'train-00150-of-00969-716fa68bbf524716.parquet', 'train-00947-of-00969-dc7975d3cf81ea24.parquet', 'train-00358-of-00969-44eaa5fa300789df.parquet', 'train-00532-of-00969-d603b40eac07bd70.parquet', 'train-00678-of-00969-5ec96baa58673d79.parquet', 'train-00402-of-00969-6ecf7ef39b90d745.parquet', 'train-00672-of-00969-eed9ea15df5515f9.parquet', 'train-00770-of-00969-6e04004ef3a12f40.parquet', 'train-00272-of-00969-4e5d95e6b0e64282.parquet', 'train-00300-of-00969-ae77d27ba406ac80.parquet', 'train-00031-of-00969-da6f92bab1d029ac.parquet', 'train-00248-of-00969-3a1267b8893d50d0.parquet', 'train-00467-of-00969-a92a643993c91959.parquet', 'train-00940-of-00969-4ce58e446f1bdcdb.parquet', 'train-00234-of-00969-561d30af848c3913.parquet', 'train-00724-of-00969-e9614d0cf008137d.parquet', 'train-00038-of-00969-7170957ccaed54f8.parquet', 'train-00355-of-00969-4b1d777d2d2315af.parquet', 'train-00276-of-00969-e4cbf4d12b6ea250.parquet', 'train-00260-of-00969-96faa8b8c84f1112.parquet', 'train-00938-of-00969-6fd93688fb07b754.parquet', 'train-00048-of-00969-3d714367084b61ee.parquet', 'train-00935-of-00969-9c19c428a3c08dc6.parquet', 'train-00750-of-00969-15162372e9267d99.parquet', 'train-00690-of-00969-88351126ceaf7df7.parquet', 'train-00810-of-00969-d711e1d6ccc2cb07.parquet', 'train-00564-of-00969-93bd87c25df91fcc.parquet', 'train-00111-of-00969-30569beb75fbacf8.parquet', 'train-00371-of-00969-7213842b1925f328.parquet', 'train-00382-of-00969-f83ede52d72af5c9.parquet', 'train-00597-of-00969-17175ba636dc35c8.parquet', 'train-00364-of-00969-e6a548d42b2306be.parquet', 'train-00314-of-00969-2f511cfb9159d46a.parquet', 'train-00701-of-00969-0b5ac3bc867c71ff.parquet', 'train-00707-of-00969-7d4ba63d8f6ba798.parquet', 'train-00194-of-00969-ff4b903cdb37dbf4.parquet', 'train-00637-of-00969-95d2cd526ac2942f.parquet', 'train-00491-of-00969-383be43bf2c94fe5.parquet', 'train-00806-of-00969-18ff10987cec5bcd.parquet', 'train-00292-of-00969-e1c0beb5917dfbe1.parquet', 'train-00102-of-00969-23835b3d699776a4.parquet', 'train-00484-of-00969-4ab2d306c0f0eaac.parquet', 'train-00271-of-00969-d8b0b39c552ff7ff.parquet', 'train-00934-of-00969-c208de1daa0a02e8.parquet', 'train-00475-of-00969-3a9b454cf07de877.parquet', 'train-00247-of-00969-527740d0b0a9b343.parquet', 'train-00119-of-00969-13beda3441f804f4.parquet', 'train-00611-of-00969-7aada4a116f31bd4.parquet', 'train-00870-of-00969-738536c16580457f.parquet', 'train-00014-of-00969-b7072a92795e48a3.parquet', 'train-00200-of-00969-fc1bfa93ba3a202a.parquet', 'train-00562-of-00969-57b9ea8d599db40f.parquet', 'train-00477-of-00969-a03bcb793f8d6441.parquet', 'train-00878-of-00969-22ba0c35effadd68.parquet', 'train-00204-of-00969-fafe4b7ef0cbbb0a.parquet', 'train-00151-of-00969-7f8446bd464e2c1b.parquet', 'train-00427-of-00969-90cb40a6ed09ee1b.parquet', 'train-00712-of-00969-809c36e71fdc6264.parquet', 'train-00877-of-00969-c0f74f07c8ed305b.parquet', 'train-00006-of-00969-47ee177e5b68bde5.parquet', 'train-00015-of-00969-c682859320f82717.parquet', 'train-00958-of-00969-27d3cb40056a5dac.parquet', 'train-00116-of-00969-62eee0511ffe46ea.parquet', 'train-00526-of-00969-9a665c31bca8361a.parquet', 'train-00539-of-00969-edf2be9b15fb58eb.parquet', 'train-00284-of-00969-7334691d1f485c91.parquet', 'train-00856-of-00969-caf3c80110da0d20.parquet', 'train-00134-of-00969-d85f54a5a6166193.parquet', 'train-00875-of-00969-c95f0cad4e4d4527.parquet', 'train-00085-of-00969-f4643934b3eae428.parquet', 'train-00316-of-00969-16ca9e50ed6a608e.parquet', 'train-00466-of-00969-80e421627ee1c708.parquet', 'train-00421-of-00969-b5ee34fa5ca7b36b.parquet', 'train-00545-of-00969-16b9a7314f4d2866.parquet', 'train-00618-of-00969-a18b97b2045f4486.parquet', 'train-00160-of-00969-0e7b36859e2e5243.parquet', 'train-00480-of-00969-937d180a39946a8c.parquet', 'train-00758-of-00969-1e848c867da13634.parquet', 'train-00857-of-00969-427676b846581e0b.parquet', 'train-00748-of-00969-889d26bd3f75c640.parquet', 'train-00350-of-00969-62fec6ad5dc21cb8.parquet', 'train-00152-of-00969-26f64e7b7954e6d5.parquet', 'train-00486-of-00969-83ae33b921c7cb7c.parquet', 'train-00636-of-00969-071ea42b6f59bf42.parquet', 'train-00199-of-00969-f56c17d6c755a08e.parquet', 'train-00500-of-00969-e1ecf93c1c0232cc.parquet', 'train-00581-of-00969-5ece0ee05003580d.parquet', 'train-00184-of-00969-4d5ba0570dc90f4b.parquet', 'train-00916-of-00969-20028bbef834e6c4.parquet', 'train-00175-of-00969-6ed1c462266c5024.parquet', 'train-00790-of-00969-7ee6ffaf1fbcea98.parquet', 'train-00828-of-00969-7fa0b7acc0c4455a.parquet', 'train-00013-of-00969-69270f8d46a78579.parquet', 'train-00146-of-00969-d87373aa6e446104.parquet', 'train-00103-of-00969-36781c3909462c70.parquet', 'train-00501-of-00969-5a2fc57429c17c7b.parquet', 'train-00547-of-00969-284396eae4c5c63d.parquet', 'train-00910-of-00969-ef11700f55bfd9be.parquet', 'train-00939-of-00969-2ae55ff12a3efcf7.parquet', 'train-00556-of-00969-06cd048f619801ef.parquet', 'train-00008-of-00969-9c7aa74df35dcdd2.parquet', 'train-00279-of-00969-bd195cd958a9b099.parquet', 'train-00592-of-00969-59aad470f960fd46.parquet', 'train-00214-of-00969-955b83f9373f5846.parquet', 'train-00172-of-00969-afcd4decfd7f42c1.parquet', 'train-00468-of-00969-9f2540db5995f76c.parquet', 'train-00265-of-00969-92a647ce94c56064.parquet', 'train-00646-of-00969-9dab0c815ebed52a.parquet', 'train-00933-of-00969-93824c0f4080b80a.parquet', 'train-00437-of-00969-1014e4d4a572c18d.parquet', 'train-00846-of-00969-8ca0ca6a6f32ca71.parquet', 'train-00091-of-00969-d33c24afd95d4cff.parquet', 'train-00596-of-00969-f463ada44e5f7cba.parquet', 'train-00393-of-00969-4a537c9a64ac621f.parquet', 'train-00460-of-00969-00c41627c6d68b77.parquet', 'train-00612-of-00969-dcfdb5ce5d7d18ec.parquet', 'train-00419-of-00969-c522ccc1ed030778.parquet', 'train-00743-of-00969-b3b020424f8bec63.parquet', 'train-00569-of-00969-8cd8fd31d3690a83.parquet', 'train-00353-of-00969-a1f8062dcc5bb411.parquet', 'train-00942-of-00969-b4cc29928f1cc990.parquet', 'train-00511-of-00969-d77d81f535aeb1fc.parquet', 'train-00513-of-00969-9357ab5103652743.parquet', 'train-00565-of-00969-b3ed2a44c836a361.parquet', 'train-00061-of-00969-add8228b7fa7d52a.parquet', 'train-00695-of-00969-cb69bc00c6a15493.parquet', 'train-00601-of-00969-911eb411c0a58280.parquet', 'train-00840-of-00969-1d3ff16790bc51df.parquet', 'train-00366-of-00969-30e7b5b6c234954c.parquet', 'train-00653-of-00969-2272535d1cc6b3d1.parquet', 'train-00549-of-00969-a143d8fc3e5bf1c2.parquet', 'train-00801-of-00969-ad817cc7cce9fffc.parquet', 'train-00882-of-00969-81bb4d609d3c87bd.parquet', 'train-00357-of-00969-426da0943f68826e.parquet', 'train-00197-of-00969-bab675211984302a.parquet', 'train-00090-of-00969-9a08ae399ad61604.parquet', 'train-00430-of-00969-09d9f186d13dfd60.parquet', 'train-00041-of-00969-e5834eac6ae7681a.parquet', 'train-00561-of-00969-905ea0f5f3f3497d.parquet', 'train-00017-of-00969-72e438cd51301eac.parquet', 'train-00426-of-00969-698411ad462ff4be.parquet', 'train-00384-of-00969-1d0331ec2ba0c1d6.parquet', 'train-00325-of-00969-4ad81a3e6dc281ca.parquet', 'train-00792-of-00969-5a67bf7018faf09e.parquet', 'train-00558-of-00969-c0a339534f1f466d.parquet', 'train-00462-of-00969-ded4a113a6eff2e6.parquet', 'train-00509-of-00969-a0e93b9498fc94c0.parquet', 'train-00898-of-00969-9db3fc2e8ffa5be7.parquet', 'train-00098-of-00969-0443437bb08bf5d8.parquet', 'train-00368-of-00969-14a2ba1802b60ffa.parquet', 'train-00699-of-00969-ebc1d8a64a71225a.parquet', 'train-00186-of-00969-82e2d39a4f3a69bd.parquet', 'train-00906-of-00969-6cb0e14143e4b8bc.parquet', 'train-00941-of-00969-66b1bc1e92e07508.parquet', 'train-00112-of-00969-588145c9e4217a42.parquet', 'train-00066-of-00969-c63e267f28733d3b.parquet', 'train-00157-of-00969-07fc136df598a0a8.parquet', 'train-00535-of-00969-e03599de9ae44e73.parquet', 'train-00919-of-00969-ef125731adddb134.parquet', 'train-00333-of-00969-7f4ffd8d07b96b71.parquet', 'train-00493-of-00969-5741e7502059ad8f.parquet', 'train-00643-of-00969-a508a79b2c07e309.parquet', 'train-00423-of-00969-2f3f8969029544e1.parquet', 'train-00068-of-00969-e0ff7995184eb35d.parquet', 'train-00573-of-00969-161c273c390719ef.parquet', 'train-00148-of-00969-d82a0e156180e062.parquet', 'train-00622-of-00969-217a27db2b64af5c.parquet', 'train-00767-of-00969-3e48007aeb99bb2b.parquet', 'train-00449-of-00969-0db49e2d84d7dd06.parquet', 'train-00259-of-00969-874d648ebe6062f4.parquet', 'train-00047-of-00969-2d2ceebe27447426.parquet', 'train-00410-of-00969-b79525c1c32adae3.parquet', 'train-00070-of-00969-4b3e942e3a736c86.parquet', 'train-00361-of-00969-87f586b7b47c4a46.parquet', 'train-00060-of-00969-9af510cba99e7e97.parquet', 'train-00443-of-00969-3a0e256dfbc2cbe7.parquet', 'train-00673-of-00969-83d39504b7e2df1e.parquet', 'train-00401-of-00969-f9eca625f3811440.parquet', 'train-00087-of-00969-77eccd7ecf3ad9ad.parquet', 'train-00931-of-00969-14929499bf87c045.parquet', 'train-00075-of-00969-37bf608a8b934b06.parquet', 'train-00773-of-00969-95888857bdd171c9.parquet', 'train-00189-of-00969-5db4685c81e1ed13.parquet', 'train-00128-of-00969-ec2916f4eb021cc8.parquet', 'train-00915-of-00969-ac9b99eddac2c923.parquet', 'train-00516-of-00969-4a29dcf058e44c39.parquet', 'train-00853-of-00969-571b92e3094464a4.parquet', 'train-00779-of-00969-0cc941ba66915530.parquet', 'train-00904-of-00969-4eff4b4859a64589.parquet', 'train-00786-of-00969-70c5827083a11776.parquet', 'train-00787-of-00969-acae4bc520382f27.parquet', 'train-00688-of-00969-e76054e18275dafc.parquet', 'train-00632-of-00969-4b262fb2bed972c9.parquet', 'train-00391-of-00969-88cb2b4e2692f3f4.parquet', 'train-00399-of-00969-ffb1b7e8e805c771.parquet', 'train-00567-of-00969-b58edde2cfd291d3.parquet', 'train-00705-of-00969-f0e5b40387ad6fef.parquet', 'train-00378-of-00969-5b3db8788e77160a.parquet', 'train-00037-of-00969-9425d52b2c360fb2.parquet', 'train-00681-of-00969-a67cfd3d6b5b53be.parquet', 'train-00845-of-00969-ad2bb75575fe0099.parquet', 'train-00235-of-00969-e45b78e3f9956e4e.parquet', 'train-00883-of-00969-9152f59b0a15c6e3.parquet', 'train-00193-of-00969-4c64d0aedca3420f.parquet', 'train-00072-of-00969-0e752a5ac9740931.parquet', 'train-00791-of-00969-c568a8ee37e7d8ee.parquet', 'train-00306-of-00969-4927373bfdfaeab0.parquet', 'train-00412-of-00969-80230b853ef162bf.parquet', 'train-00578-of-00969-1600eade38091a48.parquet', 'train-00413-of-00969-cda70844670e1922.parquet', 'train-00602-of-00969-28d992a2e8400a1c.parquet', 'train-00912-of-00969-08e60f5bf0ea85f3.parquet', 'train-00677-of-00969-85bd6a535141ad4b.parquet', 'train-00414-of-00969-41b22d20b6f5749b.parquet', 'train-00729-of-00969-8623873fc6a23601.parquet', 'train-00025-of-00969-7614e1493c855581.parquet', 'train-00049-of-00969-8c369541ee31dfeb.parquet', 'train-00171-of-00969-f1c73b22dd66a483.parquet', 'train-00865-of-00969-6a6013d0ba2b71e2.parquet', 'train-00926-of-00969-a202573349fa693c.parquet', 'train-00106-of-00969-eac9822b45fbc4f6.parquet', 'train-00179-of-00969-bcbf0762201ef97b.parquet', 'train-00018-of-00969-4e4a93434edfe683.parquet', 'train-00531-of-00969-afb86a661cf91732.parquet', 'train-00495-of-00969-767b199002535597.parquet', 'train-00270-of-00969-b5177e452d391d47.parquet', 'train-00230-of-00969-40bb8cdc8b636cd5.parquet', 'train-00706-of-00969-49dc8e5991d956ac.parquet', 'train-00703-of-00969-93bdba4c07b2fcb2.parquet', 'train-00210-of-00969-7e144964589e5a4d.parquet', 'train-00268-of-00969-394afca57e4f3e14.parquet', 'train-00772-of-00969-6f90831f59ee4f71.parquet', 'train-00631-of-00969-07674895e430d08c.parquet', 'train-00225-of-00969-a565214129d53064.parquet', 'train-00702-of-00969-0b2501c3473fc499.parquet', 'train-00273-of-00969-523fbe0d4fa7e793.parquet', 'train-00587-of-00969-f39a7b2482da860a.parquet', 'train-00658-of-00969-818ca06a71c66190.parquet', 'train-00626-of-00969-8050fc86d19c945c.parquet', 'train-00536-of-00969-54edc181a3895bc9.parquet', 'train-00863-of-00969-8beffcb2246cd8c3.parquet', 'train-00089-of-00969-391b96f043af7868.parquet', 'train-00563-of-00969-a364989cd92b5701.parquet', 'train-00063-of-00969-cacb5b6bca81d235.parquet', 'train-00344-of-00969-0f5bf013bcf449d0.parquet', 'train-00880-of-00969-13894e5c00227c49.parquet', 'train-00250-of-00969-39703086ca52df2d.parquet', 'train-00944-of-00969-48a0a635bc479429.parquet', 'train-00188-of-00969-9c6f518860189cbd.parquet', 'train-00293-of-00969-049f03201747abf4.parquet', 'train-00956-of-00969-df4c1dfd51d973b4.parquet', 'train-00465-of-00969-0fcd937872f6e99b.parquet', 'train-00340-of-00969-91ca7bfa1586d8ad.parquet', 'train-00642-of-00969-302c7cf461c5e2bf.parquet', 'train-00740-of-00969-44956093fea1733e.parquet', 'train-00965-of-00969-9ea105c83b0fd5e8.parquet', 'train-00634-of-00969-da652ee91e6cc516.parquet', 'train-00257-of-00969-a3f64744e5af36f0.parquet', 'train-00650-of-00969-e7b0f60ea019b070.parquet', 'train-00377-of-00969-5a2071e77248e5ff.parquet', 'train-00329-of-00969-d1d6cc9cf9ba1ab4.parquet', 'train-00223-of-00969-3192e71315c59501.parquet', 'train-00541-of-00969-0163a3a75e56153d.parquet', 'train-00362-of-00969-5f7dccbffa033243.parquet', 'train-00033-of-00969-859fa3a53a23982e.parquet', 'train-00096-of-00969-b1c4c8d034fb5211.parquet', 'train-00836-of-00969-d86b06a0a6e5d37b.parquet', 'train-00219-of-00969-8403e65b865f0a2d.parquet', 'train-00050-of-00969-6176d7c9a3991228.parquet', 'train-00928-of-00969-03c352b8a0b8faf7.parquet', 'train-00957-of-00969-761c347495a1f6e1.parquet', 'train-00383-of-00969-5c93ce7b8fc50400.parquet', 'train-00723-of-00969-1ed02313562e5033.parquet', 'train-00233-of-00969-ea1091394fb14fae.parquet', 'train-00797-of-00969-2944a7f587b3390a.parquet', 'train-00559-of-00969-f7fec730a790c6ca.parquet', 'train-00962-of-00969-3f16829b227433a0.parquet', 'train-00515-of-00969-5f358c4a1ac4d92b.parquet', 'train-00177-of-00969-ac96d6b9458925ae.parquet', 'train-00132-of-00969-b82b8243c8a829b4.parquet', 'train-00390-of-00969-32b656525875e0e7.parquet', 'train-00269-of-00969-9bd8a24f172a72f6.parquet', 'train-00432-of-00969-c405c8b010b74b98.parquet', 'train-00814-of-00969-e8a0b793bc902ee0.parquet', 'train-00261-of-00969-be4beeb83a8d002c.parquet', 'train-00816-of-00969-a2791ea0ca4435b7.parquet', 'train-00338-of-00969-c7c9c90f5b67b741.parquet', 'train-00217-of-00969-71ab0b5c69a19f49.parquet', 'train-00823-of-00969-a3dfa624b28c2a17.parquet', 'train-00508-of-00969-29fd28bd27d8aee8.parquet', 'train-00943-of-00969-798faacc6bd98fde.parquet', 'train-00661-of-00969-3d4c632e5e04ef32.parquet', 'train-00864-of-00969-950e2edde8843c95.parquet', 'train-00287-of-00969-12e95ce22129faea.parquet', 'train-00029-of-00969-96f2b402166faeee.parquet', 'train-00736-of-00969-f1e01b3dada61566.parquet', 'train-00026-of-00969-47d24b557d276ae0.parquet', 'train-00198-of-00969-30e058031795665b.parquet', 'train-00169-of-00969-c78d4eed5de9a876.parquet', 'train-00385-of-00969-6eabee1cef84e043.parquet', 'train-00135-of-00969-9210884a773c0656.parquet', 'train-00640-of-00969-80067a6225056a8f.parquet', 'train-00381-of-00969-7c4d95e4b8d96444.parquet', 'train-00373-of-00969-0aa857b82167de86.parquet', 'train-00348-of-00969-cdfd4948774eb807.parquet', 'train-00372-of-00969-e3dda35b10e9e021.parquet', 'train-00457-of-00969-52bb22a84c1cbb19.parquet', 'train-00749-of-00969-5ddfaf43586d3331.parquet', 'train-00242-of-00969-058971b318cb0c01.parquet', 'train-00734-of-00969-b48c80aa7caed2c5.parquet', 'train-00867-of-00969-074d85ca5fa7ef22.parquet', 'train-00411-of-00969-259f1f00735b959e.parquet', 'train-00005-of-00969-db202d0a761d36d1.parquet', 'train-00315-of-00969-7da89ddf2930c073.parquet', 'train-00345-of-00969-672bc07d0c4753e6.parquet', 'train-00482-of-00969-a9b4ed229b901e30.parquet', 'train-00793-of-00969-0afd9fb160da2eca.parquet', 'train-00946-of-00969-8a84cb9f337c58b3.parquet', 'train-00139-of-00969-15d8cc3d7516776b.parquet', 'train-00187-of-00969-b2015b32c13fdf8f.parquet', 'train-00422-of-00969-f309c819222205e0.parquet', 'train-00438-of-00969-0f6a7b45e7e90840.parquet', 'train-00288-of-00969-8c10975a59e30921.parquet', 'train-00554-of-00969-064f7d1a68b54c19.parquet', 'train-00609-of-00969-4f061c8d1f339e19.parquet', 'train-00011-of-00969-cfe37b24c4a57439.parquet', 'train-00555-of-00969-22d2e5c1b57311af.parquet', 'train-00228-of-00969-a7ae4ee72609e227.parquet', 'train-00952-of-00969-8316fee93f86122b.parquet', 'train-00320-of-00969-9b279684fc28f36e.parquet', 'train-00256-of-00969-90f63e6b7d7ed605.parquet', 'train-00780-of-00969-cbaadb250bda1296.parquet', 'train-00722-of-00969-88c8faacd63af855.parquet', 'train-00408-of-00969-a0227c29cec3628d.parquet', 'train-00036-of-00969-bb4ed1de200a7b90.parquet', 'train-00959-of-00969-6b8719480c0498a8.parquet', 'train-00158-of-00969-e90b3c15f4f56782.parquet', 'train-00052-of-00969-46c6350a17ced432.parquet', 'train-00429-of-00969-d36ca4380a74de6e.parquet', 'train-00446-of-00969-cc778f2395f03f26.parquet', 'train-00651-of-00969-4e90bf0f625311a0.parquet', 'train-00604-of-00969-615c5156c44f4e89.parquet', 'train-00010-of-00969-7795cc322cb8c64b.parquet', 'train-00936-of-00969-2273f5762448edd6.parquet', 'train-00163-of-00969-221ebbb602584eb6.parquet', 'train-00374-of-00969-334fb92a7238720d.parquet', 'train-00674-of-00969-3cc492538efb2f2a.parquet', 'train-00831-of-00969-dcaaaa4e2d5fe7ac.parquet', 'train-00819-of-00969-145ce62a9d5f19e6.parquet', 'train-00669-of-00969-c254b1e5bb5529a9.parquet', 'train-00347-of-00969-a8de82787a8201b4.parquet', 'train-00138-of-00969-4942d41d70544416.parquet', 'train-00012-of-00969-05da9dc073767042.parquet', 'train-00117-of-00969-f2eae2f41a5cf560.parquet', 'train-00529-of-00969-242514f5226b1d39.parquet', 'train-00336-of-00969-57356c8bd3d50464.parquet', 'train-00717-of-00969-a7d59a8970116506.parquet', 'train-00922-of-00969-bd110012dc72b9d6.parquet', 'train-00168-of-00969-6c5022f10ed4c203.parquet', 'train-00253-of-00969-ee9f16a580b17d5a.parquet', 'train-00591-of-00969-f05ed4b26f7e9fff.parquet', 'train-00083-of-00969-cec8932b0b997279.parquet', 'train-00056-of-00969-d1cc7ebcc5e9adbd.parquet', 'train-00599-of-00969-c86366da7d19302e.parquet', 'train-00436-of-00969-92bbd363e914fc10.parquet', 'train-00330-of-00969-fbd37c6af41c9545.parquet', 'train-00538-of-00969-05d0e6cceb17ba41.parquet', 'train-00125-of-00969-48b8378c7e8f2b84.parquet', 'train-00370-of-00969-1272966eca9a40e3.parquet', 'train-00009-of-00969-9f1b1e854b06d709.parquet', 'train-00281-of-00969-26fbad9d2fa043ed.parquet', 'train-00483-of-00969-160be5184deee035.parquet', 'train-00255-of-00969-a63b6e8ec60bc837.parquet', 'train-00860-of-00969-a2a74392324e2568.parquet', 'train-00534-of-00969-9a0ab10f0037fdc9.parquet', 'train-00039-of-00969-85bfe6d4e9bb84ac.parquet', 'train-00051-of-00969-38798f70950d1969.parquet', 'train-00058-of-00969-160ce22b0fdc5e28.parquet', 'train-00045-of-00969-2ad72fddb117a30a.parquet', 'train-00733-of-00969-dac32c08a925c3ba.parquet', 'train-00824-of-00969-a01c288ea8c634f5.parquet', 'train-00387-of-00969-d64e3fc565e0363e.parquet', 'train-00711-of-00969-4ca100e7e86dbe7a.parquet', 'train-00425-of-00969-ac266bdafd74ff48.parquet', 'train-00444-of-00969-f48084cd895a3466.parquet', 'train-00667-of-00969-9c79cb3550509494.parquet', 'train-00019-of-00969-b455c005a926d98d.parquet', 'train-00294-of-00969-a5e68c84a34d5a40.parquet', 'train-00968-of-00969-1241cb5d90d78364.parquet', 'train-00704-of-00969-e69b5d4b5253bcc7.parquet', 'train-00668-of-00969-d7c6da6286810910.parquet', 'train-00183-of-00969-f8b60c88a11fb7a5.parquet', 'train-00528-of-00969-c2f8d4a766ccc8f3.parquet', 'train-00892-of-00969-e42c3074475e0d1d.parquet', 'train-00751-of-00969-547fab7117a0435f.parquet', 'train-00076-of-00969-525a228e3d5b6855.parquet', 'train-00524-of-00969-bfb9fbafc9504db8.parquet', 'train-00663-of-00969-a877d3694c32ea75.parquet', 'train-00099-of-00969-f348678fa1f757b2.parquet', 'train-00479-of-00969-d278383e2423ed23.parquet', 'train-00406-of-00969-abb24b5e56510471.parquet', 'train-00262-of-00969-b0056797d33bf120.parquet', 'train-00311-of-00969-cc6e73a53117a96d.parquet', 'train-00211-of-00969-7b620647da628252.parquet', 'train-00415-of-00969-8c092b7a3a3376fd.parquet', 'train-00307-of-00969-5b355228837fd38f.parquet', 'train-00514-of-00969-ecdd205032e8a324.parquet', 'train-00481-of-00969-8abf6cd9d1229504.parquet', 'train-00829-of-00969-124654ece9db600a.parquet', 'train-00897-of-00969-fa3dd583589ebf94.parquet', 'train-00835-of-00969-a0a14aba87f40820.parquet', 'train-00955-of-00969-5c047f7d4081d9e7.parquet', 'train-00379-of-00969-0958625716d26e33.parquet', 'train-00560-of-00969-c5f9817e98380876.parquet', 'train-00619-of-00969-f3455259cb92dc24.parquet', 'train-00054-of-00969-d5038e59363febc0.parquet', 'train-00499-of-00969-dec2435b173ec296.parquet', 'train-00301-of-00969-9209fe4e9e44af2d.parquet', 'train-00000-of-00969-6666e11cc8d5b5b2.parquet', 'train-00505-of-00969-32ae8a928642dd1b.parquet', 'train-00053-of-00969-3103683a13a480f0.parquet', 'train-00496-of-00969-d37126b07c91c25a.parquet', 'train-00510-of-00969-c33b7be50a086137.parquet', 'train-00121-of-00969-0d98ae105527f92d.parquet', 'train-00879-of-00969-137409e4f6bab9e8.parquet', 'train-00896-of-00969-f46f336abd137222.parquet', 'train-00757-of-00969-655c7f25be7a71bd.parquet', 'train-00885-of-00969-4550ba31932cfc4a.parquet', 'train-00212-of-00969-71175c73b28a6be3.parquet', 'train-00664-of-00969-d99a8b1ef0073036.parquet', 'train-00752-of-00969-087f855fe3c59e6c.parquet', 'train-00349-of-00969-e6d1c198d21689ec.parquet', 'train-00804-of-00969-5d86ae339f537ef1.parquet', 'train-00071-of-00969-2db4b0f6fa93c65d.parquet', 'train-00016-of-00969-2d30145d9011306f.parquet', 'train-00161-of-00969-87d64180333ef40c.parquet', 'train-00512-of-00969-05e02ef366ddd18f.parquet', 'train-00094-of-00969-52695a4fc32d1e1c.parquet', 'train-00709-of-00969-517a44d823762109.parquet', 'train-00007-of-00969-69365faaaadec8a6.parquet', 'train-00795-of-00969-22e940ab2549a86a.parquet', 'train-00685-of-00969-0292964cf0a1b882.parquet', 'train-00932-of-00969-7033b5fdb6812b59.parquet', 'train-00518-of-00969-8b9526d85579b680.parquet', 'train-00239-of-00969-4586fc308bef27a2.parquet', 'train-00656-of-00969-d420fa97e6567829.parquet', 'train-00843-of-00969-d963a893235d60a7.parquet', 'train-00921-of-00969-495acf9b431690b3.parquet', 'train-00583-of-00969-787d146d9462dfc9.parquet', 'train-00608-of-00969-e5880cc261b802fa.parquet', 'train-00566-of-00969-bcc06d83990a54f4.parquet', 'train-00615-of-00969-815f4cd17244839b.parquet', 'train-00042-of-00969-d074cf0f2cdee582.parquet', 'train-00662-of-00969-06f25fc082d765ca.parquet', 'train-00109-of-00969-79c94083549cf8d1.parquet', 'train-00523-of-00969-4b87fca793e36256.parquet', 'train-00551-of-00969-3a54e816cbd04a38.parquet', 'train-00251-of-00969-0c3286a6bbc8b8e4.parquet', 'train-00715-of-00969-b92181633baf77c5.parquet', 'train-00937-of-00969-6de6b1fa6c431007.parquet', 'train-00418-of-00969-0e905e83f36f0f6c.parquet', 'train-00844-of-00969-4a116906738211dd.parquet', 'train-00633-of-00969-0de6900ee2f1604b.parquet', 'train-00949-of-00969-d06ba5da1c7a317f.parquet', 'train-00224-of-00969-3779584604ce18ac.parquet', 'train-00400-of-00969-304c7541fb75f09b.parquet', 'train-00861-of-00969-d3cdd50f4440eac8.parquet', 'train-00046-of-00969-0d7882f2e6836d19.parquet', 'train-00800-of-00969-c1a4a83cf91d19d8.parquet', 'train-00589-of-00969-42e9393096edc85d.parquet', 'train-00671-of-00969-49db4e383074bad3.parquet', 'train-00907-of-00969-45abf893e11c3b55.parquet', 'train-00595-of-00969-02613f0d1ceaf709.parquet', 'train-00490-of-00969-6cc70dbce17e1e24.parquet', 'train-00813-of-00969-ec3e9a5aefec1458.parquet', 'train-00032-of-00969-2dd66af35d0d2f4c.parquet', 'train-00833-of-00969-2c54193b649f8b20.parquet', 'train-00343-of-00969-f894426fe2d34841.parquet', 'train-00967-of-00969-f66091062677205e.parquet', 'train-00342-of-00969-321ac10341f07cdf.parquet', 'train-00630-of-00969-583601ba6b29b024.parquet', 'train-00660-of-00969-eacf62a6edf4e518.parquet', 'train-00899-of-00969-37b20e440aea3410.parquet', 'train-00208-of-00969-3fd917dc69e1ba67.parquet', 'train-00785-of-00969-27f923419da10d44.parquet', 'train-00304-of-00969-5a5b56ca2290ebe3.parquet', 'train-00713-of-00969-b3917a318d53bb3a.parquet', 'train-00960-of-00969-81270b462495e6fe.parquet', 'train-00808-of-00969-013715e41164c4e8.parquet', 'train-00913-of-00969-0e9a8763c34d20c4.parquet', 'train-00266-of-00969-6932e62bef008d61.parquet', 'train-00105-of-00969-bbd7b63a8e0ec313.parquet', 'train-00057-of-00969-c3753237f9913e9e.parquet', 'train-00858-of-00969-9d8fae3ff44deb39.parquet', 'train-00243-of-00969-9d091eba39e0e47d.parquet', 'train-00888-of-00969-a92d6d3654f04c55.parquet', 'train-00122-of-00969-a91b1e53c5f0dc7b.parquet', 'train-00582-of-00969-8fc70ed26bddd189.parquet', 'train-00218-of-00969-2dc00f3aa45fab2b.parquet', 'train-00614-of-00969-bfb4125262c2b0a4.parquet', 'train-00190-of-00969-9666c69e61a605b3.parquet', 'train-00893-of-00969-4e12344acc393429.parquet', 'train-00092-of-00969-aab387d3577c39be.parquet', 'train-00737-of-00969-a8b06083ff0031f2.parquet', 'train-00693-of-00969-9c60564a03a27a08.parquet', 'train-00249-of-00969-6341327767c9f530.parquet', 'train-00782-of-00969-d8df7824b1f83f51.parquet', 'train-00520-of-00969-78b8459dd7f29fca.parquet', 'train-00517-of-00969-e84322bdd5d3a2b5.parquet', 'train-00665-of-00969-da50b1ec8eca72df.parquet', 'train-00859-of-00969-179addfd9b16bcee.parquet', 'train-00303-of-00969-be26ad2e78f17230.parquet', 'train-00908-of-00969-4b0a55b488dcf429.parquet', 'train-00323-of-00969-e02d531a4cfcba1f.parquet', 'train-00544-of-00969-518bbc0d4fe0c1c8.parquet', 'train-00963-of-00969-7d9c9a7fcd6b1bd5.parquet', 'train-00720-of-00969-8c19279df8d1420d.parquet', 'train-00827-of-00969-6ff60405e0aed736.parquet', 'train-00552-of-00969-482a8fc7006f7913.parquet', 'train-00081-of-00969-1e30e32ae2be25b6.parquet', 'train-00153-of-00969-d67b805016056545.parquet', 'train-00420-of-00969-c7acd5e9a5bc3b46.parquet', 'train-00282-of-00969-2c7e2bb3b994de1f.parquet', 'train-00352-of-00969-760d95ebd53bf34a.parquet', 'train-00641-of-00969-7ee98a435d355191.parquet', 'train-00434-of-00969-b8e9364f8f13bb5d.parquet', 'train-00447-of-00969-be0cc18859551ebd.parquet', 'train-00649-of-00969-09ed89d9b787356c.parquet', 'train-00455-of-00969-7d7c562baf77dbb9.parquet', 'train-00113-of-00969-986890d0fc5454d3.parquet', 'train-00884-of-00969-d478c42421c71151.parquet', 'train-00022-of-00969-fd23c37f9d652229.parquet', 'train-00118-of-00969-8aa11494447c1cc2.parquet', 'train-00191-of-00969-2a1d355016a27262.parquet', 'train-00966-of-00969-79cacf63913c5888.parquet', 'train-00598-of-00969-9744801fc4534686.parquet', 'train-00775-of-00969-f0f9b1ba79b8bea4.parquet', 'train-00696-of-00969-6cf8636ca7708804.parquet', 'train-00742-of-00969-3519ca6ca6e9012c.parquet', 'train-00799-of-00969-82916686740b3dcf.parquet', 'train-00838-of-00969-4d177389177cd99a.parquet', 'train-00144-of-00969-6ad89662dd0eb1be.parquet', 'train-00476-of-00969-623535fd68176cad.parquet', 'train-00794-of-00969-8176defdad62b9c0.parquet', 'train-00062-of-00969-1dc0c8240c3f144c.parquet', 'train-00832-of-00969-b10e5f61613eb601.parquet', 'train-00456-of-00969-c68e77313db4181a.parquet', 'train-00730-of-00969-ef1b027a881c5e24.parquet', 'train-00143-of-00969-391a02f3681de5af.parquet', 'train-00507-of-00969-96dbbfaf375e8fb8.parquet', 'train-00768-of-00969-344b43546db11c12.parquet', 'train-00302-of-00969-d7fe61892a7b4d00.parquet', 'train-00755-of-00969-904e61e00c45b01c.parquet', 'train-00616-of-00969-fc65ad245356624a.parquet', 'train-00548-of-00969-7cd708537bc3b395.parquet', 'train-00055-of-00969-913e2aba9ef01309.parquet', 'train-00227-of-00969-71ab483331a8a957.parquet', 'train-00628-of-00969-bd93600d3b35cd75.parquet', 'train-00655-of-00969-fb0c7135a9fa6f9b.parquet', 'train-00428-of-00969-230cb08dc4b4ddb0.parquet', 'train-00876-of-00969-c07b696f8b3cad4b.parquet', 'train-00684-of-00969-66997f6118805889.parquet', 'train-00363-of-00969-de997e19e5311fab.parquet', 'train-00182-of-00969-c0ee177570030def.parquet', 'train-00930-of-00969-ca4e3df0a5c128b8.parquet', 'train-00380-of-00969-55727be3a64ab03b.parquet', 'train-00078-of-00969-af5a9764c2e6ee01.parquet', 'train-00448-of-00969-c3506fafd88c9bf1.parquet', 'train-00474-of-00969-fff423519b69b3b9.parquet', 'train-00872-of-00969-a223f19b18d78a4c.parquet', 'train-00579-of-00969-6fd1099be9793619.parquet', 'train-00900-of-00969-9e3faf2d5e54e97e.parquet', 'train-00700-of-00969-0ab9a386017f4802.parquet', 'train-00439-of-00969-5ff7ed25a813fde6.parquet', 'train-00854-of-00969-259bf6fc58c6d272.parquet', 'train-00024-of-00969-45b2b7e7f61c3a20.parquet', 'train-00229-of-00969-13ac53367c0e7226.parquet', 'train-00657-of-00969-8ea382c8be460db2.parquet', 'train-00067-of-00969-9ac29239b324721e.parquet', 'train-00489-of-00969-69771d2a37d99143.parquet', 'train-00392-of-00969-8da754ba362af22e.parquet', 'train-00753-of-00969-e6ddae5f891b4907.parquet', 'train-00659-of-00969-798559f1dcc421b2.parquet', 'train-00621-of-00969-68457b24d9cba344.parquet', 'train-00765-of-00969-04f1d2377410b232.parquet', 'train-00445-of-00969-5b807a1748c30bcb.parquet', 'train-00464-of-00969-9b10d27dcf526279.parquet', 'train-00754-of-00969-225914d1ce9bf741.parquet', 'train-00180-of-00969-960206bb1d7dd376.parquet', 'train-00771-of-00969-563b0ed253303f7c.parquet', 'train-00394-of-00969-8442999e1f84b5c8.parquet', 'train-00131-of-00969-3a1f4b0a57496a3e.parquet', 'train-00278-of-00969-5fd2679262f6bd39.parquet', 'train-00398-of-00969-79ec6b58386aa2b9.parquet', 'train-00074-of-00969-4cc85717581472db.parquet', 'train-00887-of-00969-22c0fc1d42dd860e.parquet', 'train-00852-of-00969-ffc1fd1dff97adaf.parquet', 'train-00851-of-00969-e8edd2623c06ca8c.parquet', 'train-00763-of-00969-e88c3e924801d707.parquet', 'train-00310-of-00969-f065b4eb96687767.parquet', 'train-00694-of-00969-dfec69b1a1a990ea.parquet', 'train-00021-of-00969-f589398bf0661979.parquet', 'train-00295-of-00969-ba6908ef743e9be4.parquet', 'train-00231-of-00969-117ede670b81267a.parquet', 'train-00719-of-00969-e1ccc5810eaedd66.parquet', 'train-00313-of-00969-0953e17b3df7904e.parquet', 'train-00386-of-00969-adb2eb1e879341ba.parquet', 'train-00403-of-00969-95ff17e6d6252452.parquet', 'train-00305-of-00969-494a3306a9559d27.parquet', 'train-00905-of-00969-a29068808e43c6d1.parquet', 'train-00141-of-00969-5eb39f1b2186ae1d.parquet', 'train-00874-of-00969-36a05e4a202e414e.parquet', 'train-00433-of-00969-b960951cb6c47a7d.parquet', 'train-00192-of-00969-6a6f6662b2f0804c.parquet', 'train-00458-of-00969-81db9834f582243c.parquet', 'train-00580-of-00969-9462bd8fdc962a0c.parquet', 'train-00769-of-00969-7a2283d6973aad92.parquet', 'train-00760-of-00969-18c6e54c81ed1246.parquet', 'train-00084-of-00969-fd06b0801bc2f52d.parquet', 'train-00830-of-00969-b95fb1693828c63b.parquet', 'train-00679-of-00969-cfd072a456680197.parquet', 'train-00623-of-00969-33512bd18c468801.parquet', 'train-00774-of-00969-a20cf3ad1c5f49c8.parquet', 'train-00469-of-00969-099f3031f1f0bbaa.parquet', 'train-00727-of-00969-ca8f701346bbdf65.parquet', 'train-00911-of-00969-90039b7aef331f16.parquet', 'train-00603-of-00969-3eeced071c31e896.parquet', 'train-00784-of-00969-c4fe2073fa6787cd.parquet', 'train-00002-of-00969-af8eab45b8175bf8.parquet', 'train-00747-of-00969-6a8845139e393646.parquet', 'train-00881-of-00969-f47663391980b548.parquet', 'train-00890-of-00969-5b3e28ca91b30c2a.parquet', 'train-00620-of-00969-b56d9cb0277e2303.parquet', 'train-00903-of-00969-57e4b00e41c3b91b.parquet', 'train-00839-of-00969-494c09ef288e7ba7.parquet', 'train-00328-of-00969-ffde3e713a82e14c.parquet', 'train-00004-of-00969-48f41a72ccaf5426.parquet', 'train-00156-of-00969-c69491a06c1376d9.parquet', 'train-00575-of-00969-adf1d4729b269861.parquet', 'train-00154-of-00969-41eed02745c01e9d.parquet', 'train-00586-of-00969-47bb9a91ca465785.parquet', 'train-00716-of-00969-a64d4629550ef611.parquet', 'train-00213-of-00969-ad6c367ebbd42900.parquet', 'train-00920-of-00969-4e5dd5abf350b669.parquet', 'train-00488-of-00969-a2314c632f6214f6.parquet', 'train-00525-of-00969-2fed204bcd604a79.parquet', 'train-00533-of-00969-27d080a86a41428a.parquet', 'train-00335-of-00969-8bfd07c0bc1dc50b.parquet', 'train-00164-of-00969-8b5358b5ccdff4b0.parquet', 'train-00776-of-00969-d38aae73e0412436.parquet', 'train-00035-of-00969-983c8cb9307cf13c.parquet', 'train-00167-of-00969-0d4a8a95b24153a8.parquet', 'train-00069-of-00969-f4f99760542c0052.parquet', 'train-00334-of-00969-774c47db3a77564e.parquet', 'train-00100-of-00969-9fd1ec047a6d551f.parquet', 'train-00487-of-00969-0dbb3eb7ffa8393f.parquet', 'train-00221-of-00969-d31fd53aac50e7de.parquet', 'train-00841-of-00969-0764b777281a1b31.parquet', 'train-00093-of-00969-2e7c2efa6699391a.parquet', 'train-00236-of-00969-68da4795d49ab384.parquet', 'train-00453-of-00969-cf0d7c3eb10313fc.parquet', 'train-00238-of-00969-81c57d931a7aac31.parquet', 'train-00195-of-00969-eee3821a59f6710e.parquet', 'train-00471-of-00969-b6a50113bb18805c.parquet', 'train-00698-of-00969-ece891b8f7efe173.parquet', 'train-00600-of-00969-90baefa44fa21d92.parquet', 'train-00185-of-00969-9a49b9865dc45254.parquet', 'train-00417-of-00969-f8b88ffbf11f0d80.parquet', 'train-00670-of-00969-5b35225f46773895.parquet', 'train-00778-of-00969-8f0baceb48b11c01.parquet', 'train-00909-of-00969-1bd15a0863da588a.parquet', 'train-00356-of-00969-9160c7597f854e28.parquet', 'train-00297-of-00969-2dccca8049f9dc36.parquet', 'train-00124-of-00969-fa43aee997bb5811.parquet', 'train-00689-of-00969-65e2d5b2a21943e6.parquet', 'train-00290-of-00969-35c948aee98987d2.parquet', 'train-00332-of-00969-d4078fa23a2c5fc1.parquet', 'train-00927-of-00969-90b1123b610b25b1.parquet', 'train-00781-of-00969-088c65b152d58732.parquet', 'train-00283-of-00969-c8e7c377b537a0a8.parquet', 'train-00647-of-00969-3f08be1703069da7.parquet', 'train-00149-of-00969-5643b29568da8695.parquet', 'train-00802-of-00969-00e596c9c986858c.parquet', 'train-00572-of-00969-cafbe21ea301ac60.parquet', 'train-00322-of-00969-e5cfe459d1d39260.parquet', 'train-00644-of-00969-ebc5860005c5648b.parquet', 'train-00918-of-00969-0ce59cc3e2a203fa.parquet', 'train-00574-of-00969-eb131a67d3c911b3.parquet', 'train-00777-of-00969-18a303f24b34b6ac.parquet', 'train-00206-of-00969-06af8374f9f36973.parquet', 'train-00240-of-00969-b85394332a436584.parquet', 'train-00339-of-00969-e3b32635ae939c8c.parquet', 'train-00215-of-00969-1150cfd36173cdb0.parquet', 'train-00354-of-00969-a4232e1dce51f553.parquet', 'train-00546-of-00969-eebcbab6fcd02c5a.parquet', 'train-00842-of-00969-121954b20d10fc86.parquet', 'train-00714-of-00969-6d70ef15e311ef80.parquet', 'train-00296-of-00969-256864f7fd09579f.parquet', 'train-00407-of-00969-8811042f05377a82.parquet', 'train-00759-of-00969-f3c3bd99339ba00c.parquet', 'train-00003-of-00969-b87946790e5f5321.parquet', 'train-00721-of-00969-4b14c3f54ce2cd94.parquet', 'train-00550-of-00969-b8d9d52bf0d5e2e3.parquet', 'train-00431-of-00969-ecf9a230b77178c9.parquet', 'train-00687-of-00969-e8c98c3e00f0dbde.parquet', 'train-00766-of-00969-cd50871c6bf4ad36.parquet', 'train-00617-of-00969-819b5e42b37442ba.parquet', 'train-00440-of-00969-6af2df00e8a51f92.parquet', 'train-00686-of-00969-5d51692a09ddeb65.parquet', 'train-00924-of-00969-8b497712c018983e.parquet', 'train-00731-of-00969-72cfe2fbcbfcb246.parquet', 'train-00044-of-00969-ddd61c791367da1a.parquet', 'train-00901-of-00969-4f09f20505725808.parquet', 'train-00543-of-00969-dda9f331bf31b2e1.parquet', 'train-00537-of-00969-9d858d592813a239.parquet', 'train-00389-of-00969-c32b6b3f1a20945a.parquet', 'train-00498-of-00969-04e13e547e0be2ab.parquet', 'train-00571-of-00969-c86de2eb120b9c69.parquet', 'train-00593-of-00969-c380f451aa4241a7.parquet', 'train-00285-of-00969-622c08209c6d80ee.parquet', 'train-00254-of-00969-ef9be2a9b2e657e4.parquet', 'train-00166-of-00969-73c2be8d12f2d77f.parquet', 'train-00964-of-00969-c8607401d2ae5dce.parquet', 'train-00114-of-00969-32cf2e1e472ac910.parquet', 'train-00925-of-00969-1a3e710e34b23e4f.parquet', 'train-00610-of-00969-7fc043944c0a7c6c.parquet', 'train-00396-of-00969-f675e1b41d88fc88.parquet', 'train-00108-of-00969-aa6a85f30af75e6c.parquet', 'train-00308-of-00969-d4992f99f2ea6406.parquet', 'train-00576-of-00969-4998ca409a4accfd.parquet', 'train-00470-of-00969-7f6b97e3a6924dd8.parquet', 'train-00676-of-00969-a4f129efd6ea162f.parquet', 'train-00023-of-00969-15b80ceb36351214.parquet', 'train-00710-of-00969-e7a4f17ce7679869.parquet', 'train-00849-of-00969-faba33f554952dc6.parquet', 'train-00494-of-00969-a781c78b71ee1e10.parquet', 'train-00577-of-00969-8c5db1fc4d2b6f8e.parquet', 'train-00923-of-00969-b2910ca2493119f7.parquet', 'train-00165-of-00969-4d5ee66f6236e49c.parquet', 'train-00607-of-00969-2050bfbfdfad4f1d.parquet', 'train-00077-of-00969-c803f64e077779bb.parquet', 'train-00584-of-00969-7fc0d6e47423f734.parquet', 'train-00506-of-00969-9f957c137f7672a2.parquet', 'train-00811-of-00969-e3e3d39289ce1185.parquet', 'train-00178-of-00969-58d678b244b2ff05.parquet', 'train-00216-of-00969-6eb039b0421f50e0.parquet', 'train-00220-of-00969-d62c44f193edbdab.parquet', 'train-00258-of-00969-9502d8923189fb36.parquet', 'train-00359-of-00969-33d327dd74b17664.parquet', 'train-00162-of-00969-132b2935e434eb1b.parquet', 'train-00147-of-00969-2448133206cd60b3.parquet', 'train-00142-of-00969-6ee124eb7c3db7af.parquet', 'train-00527-of-00969-cdc5fb5f0a2a9c20.parquet', 'train-00817-of-00969-84e438fd5a9f81db.parquet', 'train-00312-of-00969-39d1a7d051e38711.parquet', 'train-00365-of-00969-d7d7121a9cc4d3cb.parquet', 'train-00326-of-00969-e57618451b162ba7.parquet', 'train-00244-of-00969-7e00462a8cf4e380.parquet', 'train-00692-of-00969-c46a477f5fb7d89c.parquet', 'train-00319-of-00969-d6cbe6d37cffcd46.parquet', 'train-00542-of-00969-a96079de0704305d.parquet', 'train-00409-of-00969-58a856f6206779b5.parquet', 'train-00818-of-00969-30585811982720cb.parquet', 'train-00821-of-00969-ba316361fd5db630.parquet', 'train-00871-of-00969-34788f37aed43b91.parquet', 'train-00762-of-00969-4910657ea12d3c6f.parquet', 'train-00028-of-00969-ffea07831c47ce98.parquet', 'train-00424-of-00969-40d939f09fd7b695.parquet', 'train-00492-of-00969-97d37cf3c6a870ea.parquet', 'train-00540-of-00969-20d3f76f96e6d170.parquet', 'train-00951-of-00969-c515a4a672abb212.parquet', 'train-00065-of-00969-1b6501758e5f5897.parquet', 'train-00289-of-00969-8c68e7bac72f280b.parquet', 'train-00133-of-00969-ecbcce6b1a85f817.parquet', 'train-00203-of-00969-a6df0b2a79ea7ce0.parquet', 'train-00452-of-00969-bca7019b22a42ffc.parquet', 'train-00129-of-00969-6a3b9d35a0db7244.parquet', 'train-00299-of-00969-bb7e08a1c059b962.parquet', 'train-00756-of-00969-fcb302f9f38ea174.parquet', 'train-00416-of-00969-667ea6ea83faa5ec.parquet', 'train-00745-of-00969-96ddc3b3a70a4132.parquet', 'train-00327-of-00969-9b727b65f8a10831.parquet', 'train-00891-of-00969-64efd749614af393.parquet', 'train-00953-of-00969-2fb0f39528666a19.parquet', 'train-00652-of-00969-a272c60804f0648c.parquet', 'train-00080-of-00969-3f039adc0a3ac88b.parquet', 'train-00043-of-00969-15b1b62f5b28fd20.parquet', 'train-00502-of-00969-191aa189af65517b.parquet', 'train-00809-of-00969-c2b179cb6342dcb1.parquet', 'train-00504-of-00969-ad236b4b6c3079c9.parquet', 'train-00744-of-00969-16b95b4c564fa741.parquet', 'train-00895-of-00969-a188b19f57b96bba.parquet', 'train-00059-of-00969-93131fb8a1c283af.parquet', 'train-00796-of-00969-aa2ec38755520d80.parquet', 'train-00902-of-00969-6e49ddf59755e884.parquet', 'train-00317-of-00969-ff47b552353d4f1d.parquet', 'train-00367-of-00969-3e82454d6dd60cf3.parquet', 'train-00435-of-00969-8fc227dc4b0420a2.parquet', 'train-00369-of-00969-4a478bbc838086bf.parquet', 'train-00739-of-00969-36727c407c64180c.parquet', 'train-00207-of-00969-064b2aab233c1ff1.parquet', 'train-00847-of-00969-cae5ef9c916d0a45.parquet', 'train-00521-of-00969-e83c1334bf172b35.parquet', 'train-00725-of-00969-d2dcbc045064dd16.parquet', 'train-00522-of-00969-226f884265cbd185.parquet', 'train-00680-of-00969-0e14d9d7e5b82b37.parquet', 'train-00764-of-00969-35b0f642ab9f5b63.parquet', 'train-00140-of-00969-abc5a5229cf5d545.parquet', 'train-00226-of-00969-60727cf1f3146760.parquet', 'train-00088-of-00969-7cb5bf68312faa75.parquet', 'train-00110-of-00969-43661d94f2e20527.parquet', 'train-00170-of-00969-ba5f5a7ac94cd4de.parquet', 'train-00388-of-00969-4458b685b464003c.parquet', 'train-00585-of-00969-89f7c3d7487f63a9.parquet', 'train-00675-of-00969-88f4d4904a32ddc9.parquet', 'train-00815-of-00969-8bf76cca91b5fed7.parquet', 'train-00040-of-00969-cd3ca02a30850559.parquet', 'train-00291-of-00969-b19eb2b7f247e110.parquet', 'train-00086-of-00969-fa276b59ab03a6ef.parquet', 'train-00441-of-00969-6f2577457e604293.parquet', 'train-00442-of-00969-0d1d8f66982b6c18.parquet', 'train-00503-of-00969-eefcbdcacc142b34.parquet', 'train-00557-of-00969-672e5027708a26e5.parquet', 'train-00726-of-00969-f3e8ad063a2ca92f.parquet', 'train-00030-of-00969-588de19ae8b47da4.parquet', 'train-00639-of-00969-abc6d9fd11ebc583.parquet', 'train-00654-of-00969-1e9008e04979e240.parquet', 'train-00196-of-00969-4f6e4373fde9087f.parquet', 'train-00741-of-00969-6582ee00e2fc89f4.parquet', 'train-00123-of-00969-e9d51d69b8fbdb01.parquet', 'train-00079-of-00969-352f3c81f1521255.parquet', 'train-00205-of-00969-b8b55dfb94d054f7.parquet', 'train-00805-of-00969-a20e417ff48fbefb.parquet', 'train-00181-of-00969-373543f3624917b6.parquet', 'train-00001-of-00969-a24dd29afdddfdb8.parquet', 'train-00627-of-00969-c1220ff276afca02.parquet', 'train-00746-of-00969-5182be48592130fb.parquet', 'train-00097-of-00969-36be160bce47887f.parquet', 'train-00027-of-00969-bd8ac3027f654b5b.parquet', 'train-00252-of-00969-301624b617559aa5.parquet', 'train-00126-of-00969-859a2eef7995d001.parquet', 'train-00263-of-00969-828d875ed495f89b.parquet', 'train-00246-of-00969-1f54aeb28cc884bc.parquet', 'train-00590-of-00969-45b585ebf7087afd.parquet', 'train-00277-of-00969-0e6bbde891f1f125.parquet', 'train-00728-of-00969-4135c789bcee9c45.parquet', 'train-00201-of-00969-e37b171abd908d05.parquet', 'train-00834-of-00969-9dc4f2ccd1ab73c1.parquet', 'train-00697-of-00969-21425319bcb1167e.parquet', 'train-00945-of-00969-88fc46ff1a98a093.parquet', 'train-00346-of-00969-e848d0d768bdacfd.parquet', 'train-00280-of-00969-a2d441650b486bc2.parquet', 'train-00360-of-00969-9cbabacd1d47791c.parquet', 'train-00917-of-00969-1a7aeede090bdf7f.parquet', 'train-00638-of-00969-50d960f176e9623d.parquet', 'train-00461-of-00969-2ffc9e2dada97d3c.parquet', 'train-00298-of-00969-e922696d0eac4f3a.parquet', 'train-00159-of-00969-9addc1a15a11e2d9.parquet', 'train-00020-of-00969-04e93e08658b5b28.parquet', 'train-00459-of-00969-16da8719e448ddd6.parquet', 'train-00267-of-00969-36b7bdc45acd8786.parquet', 'train-00606-of-00969-bd80333edadd8e68.parquet', 'train-00115-of-00969-741b9f266a887c10.parquet', 'train-00375-of-00969-b0483bc1d90809bc.parquet', 'train-00625-of-00969-33f980af89358047.parquet', 'train-00530-of-00969-aab1346f8367b048.parquet', 'train-00104-of-00969-4ff1e0876c0f94c1.parquet', 'train-00848-of-00969-8d5a4b08c578dfff.parquet', 'train-00822-of-00969-738a7e807ed89d94.parquet', 'train-00862-of-00969-f7049801f8dcc645.parquet', 'train-00826-of-00969-07ee4b88131a776f.parquet', 'train-00397-of-00969-8c7dae00c711eb7b.parquet', 'train-00472-of-00969-e7a4b6cfc9612bea.parquet', 'train-00519-of-00969-2e5d9029417fb30d.parquet', 'train-00594-of-00969-8b244d468ab43496.parquet', 'train-00624-of-00969-be3922be8a49b184.parquet', 'train-00812-of-00969-53b7c281d9cd0082.parquet', 'train-00136-of-00969-cd0342104f7ca050.parquet', 'train-00073-of-00969-556b06f825d0bee9.parquet', 'train-00798-of-00969-cd7781f915b75b71.parquet', 'train-00286-of-00969-84953145414ba011.parquet', 'train-00718-of-00969-1ca01edb18a1e3c1.parquet', 'train-00232-of-00969-9efc1359f4b48c32.parquet', 'train-00682-of-00969-dc3cc7da9151c651.parquet', 'train-00451-of-00969-9339c8b0b3b1a0e4.parquet', 'train-00783-of-00969-5e26d1ea1407369b.parquet', 'train-00137-of-00969-304f28f55b6950b5.parquet', 'train-00948-of-00969-1ef7db5f8b3a8421.parquet', 'train-00837-of-00969-4cf3a810de967719.parquet', 'train-00174-of-00969-d2b4de4e43a5e5f5.parquet', 'train-00395-of-00969-bfe3cd676478f69d.parquet', 'train-00473-of-00969-d1cd40db5db9bceb.parquet', 'train-00264-of-00969-66b1fd433f1ecbc7.parquet', 'train-00886-of-00969-f15bce9fa38b3328.parquet', 'train-00894-of-00969-9af76bf4b936a805.parquet', 'train-00404-of-00969-a82db3211a7614d7.parquet', 'train-00145-of-00969-ea08fac21d742192.parquet', 'train-00855-of-00969-4ec69265b0ebe337.parquet', 'train-00450-of-00969-35e3de6b74df5796.parquet', 'train-00761-of-00969-50d2dc8fd4fb9636.parquet', 'train-00732-of-00969-27e2c732747f320d.parquet', 'train-00738-of-00969-abfa1c213e712770.parquet', 'train-00588-of-00969-aa28cff1668cdc03.parquet', 'train-00950-of-00969-42ec22807e2f0d4a.parquet', 'train-00275-of-00969-d0201af4a226d391.parquet', 'train-00629-of-00969-c48ee2b4005aef86.parquet', 'train-00497-of-00969-e018b550c99447fb.parquet', 'train-00645-of-00969-1e294a6fb0dd9ce5.parquet', 'train-00331-of-00969-9da989d8aee02cbb.parquet', 'train-00478-of-00969-9a0b63efdab355bd.parquet', 'train-00127-of-00969-7f459567678c178b.parquet', 'train-00553-of-00969-a1ca0d6dd503eeb5.parquet', 'train-00850-of-00969-19d22fbf28b58bdb.parquet', 'train-00341-of-00969-74b5b05ddb9d9bc1.parquet', 'train-00914-of-00969-56d555e7fa608569.parquet', 'train-00237-of-00969-09743630ac18b550.parquet', 'train-00635-of-00969-dfb4e1641fc99d65.parquet', 'train-00788-of-00969-ea27e7bfd6a1bcec.parquet', 'train-00082-of-00969-12650994b389b1a7.parquet', 'train-00666-of-00969-98fb5b5c9bb001c7.parquet', 'train-00789-of-00969-15ec1b6ffdd820a9.parquet', 'train-00807-of-00969-e5c176b680b1dc8c.parquet', 'train-00376-of-00969-9e025617e7437d02.parquet', 'train-00454-of-00969-542d22e718b895a1.parquet', 'train-00034-of-00969-31bbed1854aab05b.parquet', 'train-00570-of-00969-1eb3c1d853718fa4.parquet', 'train-00605-of-00969-42cab126392c5811.parquet', 'train-00405-of-00969-38fef6c8baceed63.parquet', 'train-00107-of-00969-a6b105fa9f359891.parquet', 'train-00869-of-00969-6cc96dddb5ba12fb.parquet', 'train-00803-of-00969-c8b11ab8a5b9a2a9.parquet', 'train-00209-of-00969-c730fd6a3667eb70.parquet', 'train-00873-of-00969-2855aa07f4d8bf5e.parquet', 'train-00929-of-00969-53992d838294f75e.parquet', 'train-00568-of-00969-db4576c426f14863.parquet', 'train-00274-of-00969-46153b0ea05b9c5b.parquet', 'train-00318-of-00969-4d116752b109e22f.parquet', 'train-00101-of-00969-aff1195561f65385.parquet', 'train-00337-of-00969-52f5ecb476fd3a89.parquet', 'train-00222-of-00969-9837311306047160.parquet', 'train-00064-of-00969-2f09cbcd0b472f17.parquet', 'train-00173-of-00969-ed1358c03217cb12.parquet', 'train-00309-of-00969-85ab8b06f35ca8b1.parquet', 'train-00683-of-00969-b68208459d57b9c5.parquet', 'train-00954-of-00969-54950d0da8b32f91.parquet', 'train-00155-of-00969-b27112ef674cb3cf.parquet', 'train-00463-of-00969-936bfb055cddc30d.parquet', 'train-00961-of-00969-f5068c947cd16de7.parquet', 'train-00691-of-00969-4c4274a60631eab1.parquet', 'train-00321-of-00969-911a02b755a90c6e.parquet', 'train-00820-of-00969-bd44ab94faab29a9.parquet', 'train-00708-of-00969-a660f61253851ac5.parquet', 'train-00889-of-00969-b57188b0613451e1.parquet']\n# urls = [base_url+url for url in urls]\n# random.shuffle(urls)\n# streaming_animedata = load_dataset(\"parquet\", data_files={\"train\": urls}, split=\"train\", streaming=True)\n\n# # ============= LOADING DANBORU Dataset ============= #\n# base_url='https://huggingface.co/datasets/animelover/danbooru2022/resolve/main/data/'\n# urls=['data-0000.zip', 'data-0001.zip', 'data-0002.zip', 'data-0003.zip', 'data-0004.zip', 'data-0005.zip', 'data-0006.zip', 'data-0007.zip', 'data-0008.zip', 'data-0009.zip', 'data-0010.zip', 'data-0011.zip', 'data-0012.zip', 'data-0013.zip', 'data-0014.zip', 'data-0015.zip', 'data-0016.zip', 'data-0017.zip', 'data-0018.zip', 'data-0019.zip', 'data-0020.zip', 'data-0021.zip', 'data-0022.zip', 'data-0023.zip', 'data-0024.zip', 'data-0025.zip', 'data-0026.zip', 'data-0027.zip', 'data-0028.zip', 'data-0029.zip', 'data-0030.zip', 'data-0031.zip', 'data-0032.zip', 'data-0033.zip', 'data-0034.zip', 'data-0035.zip', 'data-0036.zip', 'data-0037.zip', 'data-0038.zip', 'data-0039.zip', 'data-0040.zip', 'data-0041.zip', 'data-0042.zip', 'data-0043.zip', 'data-0044.zip', 'data-0045.zip', 'data-0046.zip', 'data-0047.zip', 'data-0048.zip', 'data-0049.zip', 'data-0050.zip', 'data-0051.zip', 'data-0052.zip', 'data-0053.zip', 'data-0054.zip', 'data-0055.zip', 'data-0056.zip', 'data-0057.zip', 'data-0058.zip', 'data-0059.zip', 'data-0060.zip', 'data-0061.zip', 'data-0062.zip', 'data-0063.zip', 'data-0064.zip', 'data-0065.zip', 'data-0066.zip', 'data-0067.zip', 'data-0068.zip', 'data-0069.zip', 'data-0070.zip', 'data-0071.zip', 'data-0072.zip', 'data-0073.zip', 'data-0074.zip', 'data-0075.zip', 'data-0076.zip', 'data-0077.zip', 'data-0078.zip', 'data-0079.zip', 'data-0080.zip', 'data-0081.zip', 'data-0082.zip', 'data-0083.zip', 'data-0084.zip', 'data-0085.zip', 'data-0086.zip', 'data-0087.zip', 'data-0088.zip', 'data-0089.zip', 'data-0090.zip', 'data-0091.zip', 'data-0092.zip', 'data-0093.zip', 'data-0094.zip', 'data-0095.zip', 'data-0096.zip', 'data-0097.zip', 'data-0098.zip', 'data-0099.zip', 'data-0100.zip', 'data-0101.zip', 'data-0102.zip', 'data-0103.zip', 'data-0104.zip', 'data-0105.zip', 'data-0106.zip', 'data-0107.zip', 'data-0108.zip', 'data-0109.zip', 'data-0110.zip', 'data-0111.zip', 'data-0112.zip', 'data-0113.zip', 'data-0114.zip', 'data-0115.zip', 'data-0116.zip', 'data-0117.zip', 'data-0118.zip', 'data-0119.zip', 'data-0120.zip', 'data-0121.zip', 'data-0122.zip', 'data-0123.zip', 'data-0124.zip', 'data-0125.zip', 'data-0126.zip', 'data-0127.zip', 'data-0128.zip', 'data-0129.zip', 'data-0130.zip', 'data-0131.zip', 'data-0132.zip', 'data-0133.zip', 'data-0134.zip', 'data-0135.zip', 'data-0136.zip', 'data-0137.zip', 'data-0138.zip', 'data-0139.zip', 'data-0140.zip', 'data-0141.zip', 'data-0142.zip', 'data-0143.zip', 'data-0144.zip', 'data-0145.zip', 'data-0146.zip', 'data-0147.zip', 'data-0148.zip', 'data-0149.zip', 'data-0150.zip', 'data-0151.zip', 'data-0152.zip', 'data-0153.zip', 'data-0154.zip', 'data-0155.zip', 'data-0156.zip', 'data-0157.zip', 'data-0158.zip', 'data-0159.zip', 'data-0160.zip', 'data-0161.zip', 'data-0162.zip', 'data-0163.zip', 'data-0164.zip', 'data-0165.zip', 'data-0166.zip', 'data-0167.zip', 'data-0168.zip', 'data-0169.zip', 'data-0170.zip', 'data-0171.zip', 'data-0172.zip', 'data-0173.zip', 'data-0174.zip', 'data-0175.zip', 'data-0176.zip', 'data-0177.zip', 'data-0178.zip', 'data-0179.zip', 'data-0180.zip', 'data-0181.zip', 'data-0182.zip', 'data-0183.zip', 'data-0184.zip', 'data-0185.zip', 'data-0186.zip', 'data-0187.zip', 'data-0188.zip', 'data-0189.zip', 'data-0190.zip', 'data-0191.zip', 'data-0192.zip', 'data-0193.zip', 'data-0194.zip', 'data-0195.zip', 'data-0196.zip', 'data-0197.zip', 'data-0198.zip', 'data-0199.zip', 'data-0200.zip', 'data-0201.zip', 'data-0202.zip', 'data-0203.zip', 'data-0204.zip', 'data-0205.zip', 'data-0206.zip', 'data-0207.zip', 'data-0208.zip', 'data-0209.zip', 'data-0210.zip', 'data-0211.zip', 'data-0212.zip', 'data-0213.zip', 'data-0214.zip', 'data-0215.zip', 'data-0216.zip', 'data-0217.zip', 'data-0218.zip', 'data-0219.zip', 'data-0220.zip', 'data-0221.zip', 'data-0222.zip', 'data-0223.zip', 'data-0224.zip', 'data-0225.zip', 'data-0226.zip', 'data-0227.zip', 'data-0228.zip', 'data-0229.zip', 'data-0230.zip', 'data-0231.zip', 'data-0232.zip', 'data-0233.zip', 'data-0234.zip', 'data-0235.zip', 'data-0236.zip', 'data-0237.zip', 'data-0238.zip', 'data-0239.zip', 'data-0240.zip', 'data-0241.zip', 'data-0242.zip', 'data-0243.zip', 'data-0244.zip', 'data-0245.zip', 'data-0246.zip', 'data-0247.zip', 'data-0248.zip', 'data-0249.zip', 'data-0250.zip', 'data-0251.zip', 'data-0252.zip', 'data-0253.zip', 'data-0254.zip', 'data-0255.zip', 'data-0256.zip', 'data-0257.zip', 'data-0258.zip', 'data-0259.zip', 'data-0260.zip', 'data-0261.zip', 'data-0262.zip', 'data-0263.zip', 'data-0264.zip', 'data-0265.zip', 'data-0266.zip', 'data-0267.zip', 'data-0268.zip', 'data-0269.zip', 'data-0270.zip', 'data-0271.zip', 'data-0272.zip', 'data-0273.zip', 'data-0274.zip', 'data-0275.zip', 'data-0276.zip', 'data-0277.zip', 'data-0278.zip', 'data-0279.zip', 'data-0280.zip', 'data-0281.zip', 'data-0282.zip', 'data-0283.zip', 'data-0284.zip', 'data-0285.zip', 'data-0286.zip', 'data-0287.zip', 'data-0288.zip', 'data-0289.zip', 'data-0290.zip', 'data-0291.zip', 'data-0292.zip', 'data-0293.zip', 'data-0294.zip', 'data-0295.zip', 'data-0296.zip', 'data-0297.zip', 'data-0298.zip', 'data-0299.zip', 'data-0300.zip', 'data-0301.zip', 'data-0302.zip', 'data-0303.zip', 'data-0304.zip', 'data-0305.zip', 'data-0306.zip', 'data-0307.zip', 'data-0308.zip', 'data-0309.zip', 'data-0310.zip', 'data-0311.zip', 'data-0312.zip', 'data-0313.zip', 'data-0314.zip', 'data-0315.zip', 'data-0316.zip', 'data-0317.zip', 'data-0318.zip', 'data-0319.zip', 'data-0320.zip', 'data-0321.zip', 'data-0322.zip', 'data-0323.zip', 'data-0324.zip', 'data-0325.zip', 'data-0326.zip', 'data-0327.zip', 'data-0328.zip', 'data-0329.zip', 'data-0330.zip', 'data-0331.zip', 'data-0332.zip', 'data-0333.zip', 'data-0334.zip', 'data-0335.zip', 'data-0336.zip', 'data-0337.zip', 'data-0338.zip', 'data-0339.zip', 'data-0340.zip', 'data-0341.zip', 'data-0342.zip', 'data-0343.zip', 'data-0344.zip', 'data-0345.zip', 'data-0346.zip', 'data-0347.zip', 'data-0348.zip', 'data-0349.zip', 'data-0350.zip', 'data-0351.zip', 'data-0352.zip', 'data-0353.zip', 'data-0354.zip', 'data-0355.zip', 'data-0356.zip', 'data-0357.zip', 'data-0358.zip', 'data-0359.zip', 'data-0360.zip', 'data-0361.zip', 'data-0362.zip', 'data-0363.zip', 'data-0364.zip', 'data-0365.zip', 'data-0366.zip', 'data-0367.zip', 'data-0368.zip', 'data-0369.zip', 'data-0370.zip', 'data-0371.zip', 'data-0372.zip', 'data-0373.zip', 'data-0374.zip', 'data-0375.zip', 'data-0376.zip', 'data-0377.zip', 'data-0378.zip', 'data-0379.zip', 'data-0380.zip', 'data-0381.zip', 'data-0382.zip', 'data-0383.zip', 'data-0384.zip', 'data-0385.zip', 'data-0386.zip', 'data-0387.zip', 'data-0388.zip', 'data-0389.zip', 'data-0390.zip', 'data-0391.zip', 'data-0392.zip', 'data-0393.zip', 'data-0394.zip', 'data-0395.zip', 'data-0396.zip', 'data-0397.zip', 'data-0398.zip', 'data-0399.zip', 'data-0400.zip', 'data-0401.zip', 'data-0402.zip', 'data-0403.zip', 'data-0404.zip', 'data-0405.zip', 'data-0406.zip', 'data-0407.zip', 'data-0408.zip', 'data-0409.zip', 'data-0410.zip', 'data-0411.zip', 'data-0412.zip', 'data-0413.zip', 'data-0414.zip', 'data-0415.zip', 'data-0416.zip', 'data-0417.zip', 'data-0418.zip', 'data-0419.zip', 'data-0420.zip', 'data-0421.zip', 'data-0422.zip', 'data-0423.zip', 'data-0424.zip', 'data-0425.zip', 'data-0426.zip', 'data-0427.zip', 'data-0428.zip', 'data-0429.zip', 'data-0430.zip', 'data-0431.zip', 'data-0432.zip', 'data-0433.zip', 'data-0434.zip', 'data-0435.zip', 'data-0436.zip', 'data-0437.zip', 'data-0438.zip', 'data-0439.zip', 'data-0440.zip', 'data-0441.zip', 'data-0442.zip', 'data-0443.zip', 'data-0444.zip', 'data-0445.zip', 'data-0446.zip', 'data-0447.zip', 'data-0448.zip', 'data-0449.zip', 'data-0450.zip', 'data-0451.zip', 'data-0452.zip', 'data-0453.zip', 'data-0454.zip', 'data-0455.zip', 'data-0456.zip', 'data-0457.zip', 'data-0458.zip', 'data-0459.zip', 'data-0460.zip', 'data-0461.zip', 'data-0462.zip', 'data-0463.zip', 'data-0464.zip', 'data-0465.zip', 'data-0466.zip', 'data-0467.zip', 'data-0468.zip', 'data-0469.zip', 'data-0470.zip', 'data-0471.zip', 'data-0472.zip', 'data-0473.zip', 'data-0474.zip', 'data-0475.zip', 'data-0476.zip', 'data-0477.zip', 'data-0478.zip', 'data-0479.zip', 'data-0480.zip', 'data-0481.zip', 'data-0482.zip', 'data-0483.zip', 'data-0484.zip', 'data-0485.zip', 'data-0486.zip', 'data-0487.zip', 'data-0488.zip', 'data-0489.zip', 'data-0490.zip', 'data-0491.zip', 'data-0492.zip', 'data-0493.zip', 'data-0494.zip', 'data-0495.zip', 'data-0496.zip', 'data-0497.zip', 'data-0498.zip', 'data-0499.zip', 'data-0500.zip', 'data-0501.zip', 'data-0502.zip', 'data-0503.zip', 'data-0504.zip', 'data-0505.zip', 'data-0506.zip', 'data-0507.zip', 'data-0508.zip', 'data-0509.zip', 'data-0510.zip', 'data-0511.zip', 'data-0512.zip', 'data-0513.zip', 'data-0514.zip', 'data-0515.zip', 'data-0516.zip', 'data-0517.zip', 'data-0518.zip', 'data-0519.zip', 'data-0520.zip', 'data-0521.zip', 'data-0522.zip', 'data-0523.zip', 'data-0524.zip', 'data-0525.zip', 'data-0526.zip', 'data-0527.zip', 'data-0528.zip', 'data-0529.zip', 'data-0530.zip', 'data-0531.zip', 'data-0532.zip', 'data-0533.zip', 'data-0534.zip', 'data-0535.zip', 'data-0536.zip', 'data-0537.zip', 'data-0538.zip', 'data-0539.zip', 'data-0540.zip', 'data-0541.zip', 'data-0542.zip', 'data-0543.zip', 'data-0544.zip', 'data-0545.zip', 'data-0546.zip', 'data-0547.zip', 'data-0548.zip', 'data-0549.zip', 'data-0550.zip', 'data-0551.zip', 'data-0552.zip', 'data-0553.zip', 'data-0554.zip', 'data-0555.zip', 'data-0556.zip', 'data-0557.zip', 'data-0558.zip', 'data-0559.zip', 'data-0560.zip', 'data-0561.zip', 'data-0562.zip', 'data-0563.zip', 'data-0564.zip', 'data-0565.zip', 'data-0566.zip', 'data-0567.zip', 'data-0568.zip', 'data-0569.zip', 'data-0570.zip', 'data-0571.zip', 'data-0572.zip', 'data-0573.zip', 'data-0574.zip', 'data-0575.zip', 'data-0576.zip', 'data-0577.zip', 'data-0578.zip', 'data-0579.zip', 'data-0580.zip', 'data-0581.zip', 'data-0582.zip', 'data-0583.zip', 'data-0584.zip', 'data-0585.zip', 'data-0586.zip', 'data-0587.zip', 'data-0588.zip', 'data-0589.zip', 'data-0590.zip', 'data-0591.zip', 'data-0592.zip', 'data-0593.zip', 'data-0594.zip', 'data-0595.zip', 'data-0596.zip', 'data-0597.zip', 'data-0598.zip', 'data-0599.zip', 'data-0600.zip', 'data-0601.zip', 'data-0602.zip', 'data-0603.zip', 'data-0604.zip', 'data-0605.zip', 'data-0606.zip', 'data-0607.zip', 'data-0608.zip', 'data-0609.zip', 'data-0610.zip', 'data-0611.zip', 'data-0612.zip', 'data-0613.zip', 'data-0614.zip', 'data-0615.zip', 'data-0616.zip', 'data-0617.zip', 'data-0618.zip', 'data-0619.zip', 'data-0620.zip', 'data-0621.zip', 'data-0622.zip', 'data-0623.zip', 'data-0624.zip', 'data-0625.zip', 'data-0626.zip', 'data-0627.zip', 'data-0628.zip', 'data-0629.zip', 'data-0630.zip', 'data-0631.zip', 'data-0632.zip', 'data-0633.zip', 'data-0634.zip', 'data-0635.zip', 'data-0636.zip', 'data-0637.zip', 'data-0638.zip', 'data-0639.zip', 'data-0640.zip', 'data-0641.zip', 'data-0642.zip', 'data-0643.zip', 'data-0644.zip', 'data-0645.zip', 'data-0646.zip', 'data-0647.zip', 'data-0648.zip', 'data-0649.zip', 'data-0650.zip', 'data-0651.zip', 'data-0652.zip', 'data-0653.zip', 'data-0654.zip', 'data-0655.zip', 'data-0656.zip', 'data-0657.zip', 'data-0658.zip', 'data-0659.zip', 'data-0660.zip', 'data-0661.zip', 'data-0662.zip', 'data-0663.zip', 'data-0664.zip', 'data-0665.zip', 'data-0666.zip', 'data-0667.zip', 'data-0668.zip', 'data-0669.zip', 'data-0670.zip', 'data-0671.zip', 'data-0672.zip', 'data-0673.zip', 'data-0674.zip', 'data-0675.zip', 'data-0676.zip', 'data-0677.zip', 'data-0678.zip', 'data-0679.zip', 'data-0680.zip', 'data-0681.zip', 'data-0682.zip', 'data-0683.zip', 'data-0684.zip', 'data-0685.zip', 'data-0686.zip', 'data-0687.zip', 'data-0688.zip', 'data-0689.zip', 'data-0690.zip', 'data-0691.zip', 'data-0692.zip', 'data-0693.zip', 'data-0694.zip', 'data-0695.zip', 'data-0696.zip', 'data-0697.zip', 'data-0698.zip', 'data-0699.zip', 'data-0700.zip', 'data-0701.zip', 'data-0702.zip', 'data-0703.zip', 'data-0704.zip', 'data-0705.zip', 'data-0706.zip', 'data-0707.zip', 'data-0708.zip', 'data-0709.zip', 'data-0710.zip', 'data-0711.zip', 'data-0712.zip', 'data-0713.zip', 'data-0714.zip', 'data-0715.zip', 'data-0716.zip', 'data-0717.zip', 'data-0718.zip', 'data-0719.zip', 'data-0720.zip', 'data-0721.zip', 'data-0722.zip', 'data-0723.zip', 'data-0724.zip', 'data-0725.zip', 'data-0726.zip', 'data-0727.zip', 'data-0728.zip', 'data-0729.zip', 'data-0730.zip', 'data-0731.zip', 'data-0732.zip', 'data-0733.zip', 'data-0734.zip', 'data-0735.zip', 'data-0736.zip', 'data-0737.zip', 'data-0738.zip', 'data-0739.zip', 'data-0740.zip', 'data-0741.zip', 'data-0742.zip', 'data-0743.zip', 'data-0744.zip', 'data-0745.zip', 'data-0746.zip', 'data-0747.zip', 'data-0748.zip', 'data-0749.zip', 'data-0750.zip', 'data-0751.zip', 'data-0752.zip', 'data-0753.zip', 'data-0754.zip', 'data-0755.zip', 'data-0756.zip', 'data-0757.zip', 'data-0758.zip', 'data-0759.zip', 'data-0760.zip', 'data-0761.zip', 'data-0762.zip', 'data-0763.zip', 'data-0764.zip', 'data-0765.zip', 'data-0766.zip', 'data-0767.zip', 'data-0768.zip', 'data-0769.zip', 'data-0770.zip', 'data-0771.zip', 'data-0772.zip', 'data-0773.zip', 'data-0774.zip', 'data-0775.zip', 'data-0776.zip', 'data-0777.zip', 'data-0778.zip', 'data-0779.zip', 'data-0780.zip', 'data-0781.zip', 'data-0782.zip', 'data-0783.zip', 'data-0784.zip', 'data-0785.zip', 'data-0786.zip', 'data-0787.zip', 'data-0788.zip', 'data-0789.zip', 'data-0790.zip', 'data-0791.zip', 'data-0792.zip', 'data-0793.zip', 'data-0794.zip', 'data-0795.zip', 'data-0796.zip', 'data-0797.zip', 'data-0798.zip', 'data-0799.zip', 'data-0800.zip', 'data-0801.zip', 'data-0802.zip', 'data-0803.zip', 'data-0804.zip', 'data-0805.zip', 'data-0806.zip', 'data-0807.zip', 'data-0808.zip', 'data-0809.zip', 'data-0810.zip', 'data-0811.zip', 'data-0812.zip', 'data-0813.zip', 'data-0814.zip', 'data-0815.zip', 'data-0816.zip', 'data-0817.zip', 'data-0818.zip', 'data-0819.zip', 'data-0820.zip', 'data-0821.zip', 'data-0822.zip', 'data-0823.zip', 'data-0824.zip', 'data-0825.zip', 'data-0826.zip', 'data-0827.zip', 'data-0828.zip', 'data-0829.zip', 'data-0830.zip', 'data-0831.zip', 'data-0832.zip', 'data-0833.zip', 'data-0834.zip', 'data-0835.zip', 'data-0836.zip', 'data-0837.zip', 'data-0838.zip', 'data-0839.zip', 'data-0840.zip', 'data-0841.zip', 'data-0842.zip', 'data-0843.zip', 'data-0844.zip', 'data-0845.zip', 'data-0846.zip', 'data-0847.zip', 'data-0848.zip', 'data-0849.zip', 'data-0850.zip', 'data-0851.zip', 'data-0852.zip', 'data-0853.zip', 'data-0854.zip', 'data-0855.zip', 'data-0856.zip', 'data-0857.zip', 'data-0858.zip', 'data-0859.zip', 'data-0860.zip', 'data-0861.zip', 'data-0862.zip', 'data-0863.zip', 'data-0864.zip', 'data-0865.zip', 'data-0866.zip', 'data-0867.zip', 'data-0868.zip', 'data-0869.zip', 'data-0870.zip', 'data-0871.zip', 'data-0872.zip', 'data-0873.zip', 'data-0874.zip', 'data-0875.zip', 'data-0876.zip', 'data-0877.zip', 'data-0878.zip', 'data-0879.zip', 'data-0880.zip', 'data-0881.zip', 'data-0882.zip', 'data-0883.zip', 'data-0884.zip', 'data-0885.zip', 'data-0886.zip', 'data-0887.zip', 'data-0888.zip', 'data-0889.zip', 'data-0890.zip', 'data-0891.zip', 'data-0892.zip', 'data-0893.zip', 'data-0894.zip', 'data-0895.zip', 'data-0896.zip', 'data-0897.zip', 'data-0898.zip', 'data-0899.zip', 'data-0900.zip', 'data-0901.zip', 'data-0902.zip', 'data-0903.zip', 'data-0904.zip', 'data-0905.zip', 'data-0906.zip', 'data-0907.zip', 'data-0908.zip', 'data-0909.zip', 'data-0910.zip', 'data-0911.zip', 'data-0912.zip', 'data-0913.zip', 'data-0914.zip', 'data-0915.zip', 'data-0916.zip', 'data-0917.zip', 'data-0918.zip', 'data-0919.zip', 'data-0920.zip', 'data-0921.zip', 'data-0922.zip', 'data-0923.zip', 'data-0924.zip', 'data-0925.zip', 'data-0926.zip', 'data-0927.zip', 'data-0928.zip', 'data-0929.zip', 'data-0930.zip', 'data-0931.zip', 'data-0932.zip', 'data-0933.zip', 'data-0934.zip', 'data-0935.zip', 'data-0936.zip', 'data-0937.zip', 'data-0938.zip', 'data-0939.zip', 'data-0940.zip', 'data-0941.zip', 'data-0942.zip', 'data-0943.zip']\n# urls = [base_url+url for url in urls]\n# random.shuffle(urls)\n# streaming_danbooru = load_dataset(\"webdataset\", data_files={\"train\": urls}, split=\"train\", streaming=True)\n\n\n# stream_data='DANBOORU' # or REAL/ANIME/DANBOORU\n\n# streaming_dataset=streaming_realdata if stream_data=='REAL' else (streaming_animedata if stream_data=='ANIME' else streaming_danbooru)\n\n# #feature_extractor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n\n\n# def collate_fn(batch, tokenizer, max_length=77):\n#     images = torch.stack([item[\"image\"] for item in batch])\n#     texts = [item[\"text\"] for item in batch]\n#     # print('MaxLength:',max_length)\n#     encoded = tokenizer(\n#         texts,\n#         padding=\"max_length\",\n#         truncation=True,\n#         max_length=tokenizer.model_max_length,\n#         return_tensors=\"pt\"\n#     )\n    \n#     return {\n#         \"image\": images,\n#         \"input_ids\": encoded[\"input_ids\"],\n#         \"attention_mask\": encoded[\"attention_mask\"]\n#     }\n\n# class WebDatasetWrapper(IterableDataset):\n#     def __init__(self, dataset, feature_extractor, stream_data='REAL', max_retries=2, retry_delay=1.0):\n#         self.dataset = dataset\n#         self.feature_extractor = feature_extractor\n#         self.stream_data = stream_data\n#         self.max_retries = max_retries\n#         self.retry_delay = retry_delay\n#         self.transform = T.Compose([\n#             T.Resize(img_size),\n#             # T.CenterCrop(img_size[0]),\n#             T.ToTensor(),\n#             T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n#         ])\n\n#     def _extract_item(self, item):\n#         \"\"\"Extract image and text from raw dataset item.\"\"\"\n#         # print('ITEM:',item)\n#         if self.stream_data == 'ANIME':\n#             image = item['image']\n#             prompt = item['tags']\n#         elif self.stream_data== 'REAL':\n#             image = item['jpg']\n#             prompt = item['json']['prompt']\n#         elif self.stream_data== 'DANBOORU':\n#             image = item['jpg']\n#             prompt = item['txt']\n            \n#         return image, prompt\n\n#     def _process_item(self, item):\n#         \"\"\"Process a single item with image transform and validation.\"\"\"\n#         image, prompt = self._extract_item(item)\n        \n#         # Validate prompt\n#         if not isinstance(prompt, str) or len(prompt.strip()) == 0:\n#             raise ValueError(\"Empty or invalid prompt\")\n        \n#         # Validate and transform image\n#         if image is None:\n#             raise ValueError(\"Image is None\")\n#         transformed_image = self.transform(image)\n#         return {\"image\": transformed_image, \"text\": prompt}\n\n#     def __iter__(self):\n#         for raw_item in self.dataset:\n#             retries = 0\n#             while retries <= self.max_retries:\n#                 try:\n#                     # Attempt to process the item\n#                     yield self._process_item(raw_item)\n#                     break  # Success → exit retry loop\n\n#                 except (\n#                     ChunkedEncodingError,\n#                     ConnectionError,\n#                     ProtocolError,\n#                     IncompleteRead,\n#                     HTTPError,\n#                     OSError,  # Includes broken pipe, I/O errors\n#                     UnidentifiedImageError,  # Corrupted image\n#                     ValueError,  # Our custom validation errors\n#                     KeyError,    # Missing key like 'jpg' or 'tags'\n#                 ) as e:\n#                     retries += 1\n#                     if retries > self.max_retries:\n#                         print(f\"❌ Skipping item after {self.max_retries} retries. Error: {type(e).__name__}: {e}\")\n#                         break  # Give up and skip\n#                     else:\n#                         # Optional: exponential backoff\n#                         delay = self.retry_delay * (2 ** (retries - 1)) + random.uniform(0, 1)\n#                         print(f\"⚠️  Retry {retries}/{self.max_retries} after {delay:.2f}s due to: {e}\")\n#                         time.sleep(delay)\n#                         continue  # Try again with same item\n#                 except Exception as e:\n#                     # Unexpected error → skip immediately\n#                     print(f\"💥 Unexpected error, skipping item: {type(e).__name__}: {e}\")\n#                     break\n\n# tokenizer = CLIPTokenizer.from_pretrained(text_tokenizer_path,subfolder='tokenizer')\n# tokenizer.model_max_length=model_max_length\n# # Initialize dataset with the same feature extractor used in your code\n# dataset = WebDatasetWrapper(streaming_dataset, feature_extractor,stream_data)\n# dataloader = DataLoader(\n#     dataset,\n#     batch_size=8,\n#     # shuffle=True,\n#     num_workers=4,\n#     collate_fn=lambda b: collate_fn(b, tokenizer=tokenizer),\n#     drop_last=True\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:25.595372Z","iopub.execute_input":"2025-10-07T15:46:25.595602Z","iopub.status.idle":"2025-10-07T15:46:25.617733Z","shell.execute_reply.started":"2025-10-07T15:46:25.595584Z","shell.execute_reply":"2025-10-07T15:46:25.617022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntry:\n    for t in dataloader:\n        break\nexcept Exception as e:\n    print('Exception:',e)\nplt.imshow((t['image'][1].permute(1,2,0)+1)/2)\nprint(tokenizer.decode(t['input_ids'][1]))\nprint(len(t['input_ids'][1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:25.618552Z","iopub.execute_input":"2025-10-07T15:46:25.619144Z","iopub.status.idle":"2025-10-07T15:46:26.133186Z","shell.execute_reply.started":"2025-10-07T15:46:25.619117Z","shell.execute_reply":"2025-10-07T15:46:26.132417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom diffusers.training_utils import EMAModel\nfrom torch.amp import autocast, GradScaler\nfrom diffusers import AutoencoderKL\nfrom transformers import T5EncoderModel,CLIPTextModel, CLIPTokenizer, get_cosine_schedule_with_warmup,BertModel, BertTokenizer\nfrom diffusers.schedulers import DDPMScheduler\nfrom diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler, DDIMScheduler\nfrom diffusers.models import Transformer2DModel\nimport random\n\n# ------------------------ Parameter Counting ------------------------\ndef count_parameters(model: nn.Module, name: str = \"Model\"):\n    total = sum(p.numel() for p in model.parameters())\n    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    frozen = total - trainable\n    print(f\"[{name}] Total: {total/1e6:.2f}M | Trainable: {trainable/1e6:.2f}M | Frozen: {frozen/1e6:.2f}M\")\n    return total, trainable, frozen\n    \n# Combine all components into a single model\nclass Diffusion(nn.Module):\n    def __init__(self, vae, text_encoder, scheduler, transformer):\n        super().__init__()\n        self.vae = vae.eval()  # Freeze VAE\n        self.text_encoder = text_encoder.eval()  # Freeze text encoder\n        self.scheduler = scheduler\n        self.denoiser = transformer\n        self.vae_scale_factor=8\n        self.empty_tokens = tokenizer(\n            [\"\"],\n            padding='max_length',\n            truncation=True,\n            max_length=tokenizer.model_max_length,\n            return_tensors=\"pt\"\n        )\n        \n        # if os.path.exists(ckpt_path):\n        #     self.denoiser.load_state_dict(torch.load(ckpt_path))\n        #     print('*** Loaded denoiser weights ***')\n        \n    def forward(self, pixel_values, input_ids, attn_mask, timesteps):\n        device = timesteps.device  # <-- Get device from input\n    \n        # Ensure scheduler buffers are on the same device\n        if self.scheduler.alphas_cumprod.device != device:\n            self.scheduler.alphas_cumprod = self.scheduler.alphas_cumprod.to(device)\n            # Also move other scheduler buffers if needed\n            if hasattr(self.scheduler, 'betas'):\n                self.scheduler.betas = self.scheduler.betas.to(device)\n            if hasattr(self.scheduler, 'alphas'):\n                self.scheduler.alphas = self.scheduler.alphas.to(device)\n    \n        # 1. Encode images to latents\n        with torch.no_grad():  # VAE is frozen\n            latents = self.vae.encode(pixel_values).latent_dist.sample()\n            latents = latents * self.vae.config.scaling_factor\n    \n        if random.random() < 0.15: # for CFG\n            with torch.no_grad():\n                batch_size = input_ids.shape[0]\n                uncond_input_ids = self.empty_tokens['input_ids'].expand(batch_size, -1).to(input_ids.device)\n                uncond_attn_mask = self.empty_tokens['attention_mask'].expand(batch_size, -1).to(attn_mask.device)\n                text_embeddings = self.text_encoder(uncond_input_ids).last_hidden_state\n                attn_mask = uncond_attn_mask\n        else:\n            with torch.no_grad():  # Text encoder is frozen\n                text_embeddings = self.text_encoder(input_ids).last_hidden_state\n    \n        # 3. Add noise to latents\n        noise = torch.randn_like(latents)\n        noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)\n    \n        # 4. Predict noise\n        noise_pred = self.denoiser(\n            noisy_latents,\n            timestep=timesteps,\n            encoder_hidden_states=text_embeddings,\n            encoder_attention_mask=attn_mask\n        ).sample\n    \n        return noise_pred, noise, latents\n\n\n# Initialize components\nvae = AutoencoderKL.from_pretrained(vae_model,subfolder='vae')\ntext_encoder = T5EncoderModel.from_pretrained(text_encoder_path)\ntokenizer = AutoTokenizer.from_pretrained(text_encoder_path)\ntokenizer.model_max_length=model_max_length\n# scheduler = DDPMScheduler(**ddpm_config)\n# 4) UNet backbone\n\nconf={\n    \"activation_fn\": \"gelu-approximate\",\n  \"attention_bias\": True,\n  \"attention_head_dim\": 48,\n  \"caption_channels\": 768,\n  \"cross_attention_dim\": 768,\n  \"dropout\": 0.0,\n  \"in_channels\": 4,\n  \"norm_elementwise_affine\": False,\n  \"norm_eps\": 1e-06,\n  \"norm_num_groups\": 32,\n  \"norm_type\": \"ada_norm_single\",\n  \"num_attention_heads\": 16,\n  \"num_embeds_ada_norm\": 1000,\n  \"num_layers\": 64,\n  \"num_vector_embeds\": None,\n  \"only_cross_attention\": False,\n  \"out_channels\": 4,\n  \"patch_size\": 2,\n  \"sample_size\": 32,\n  \"upcast_attention\": False,\n  \"use_linear_projection\": True\n}\n\nscheduler = DDIMScheduler.from_pretrained('tirthadagr8/T2I_UNet',subfolder='scheduler')\ntransformer = Transformer2DModel.from_pretrained('/kaggle/input/dit_600m/transformers/default/2')\n\n# Freeze VAE and text encoder [[7]]\nvae.requires_grad_(False)\ntext_encoder.requires_grad_(False)\n\n# Enable gradient checkpointing for memory efficiency [[6]]\ntransformer.enable_gradient_checkpointing()\n# if os.path.exists(ckpt_path):\n#     transformer.load_state_dict(torch.load(ckpt_path,map_location=\"cpu\"))\n    #print('*** Loaded Transformer weights ***')\n# Enable xFormers for attention optimization [[6]]\ntry:\n    import xformers\n    transformer.enable_xformers_memory_efficient_attention()\nexcept ImportError:\n    print(\"xFormers not found; proceeding without.\")\n\n# Create combined model\nmodel = Diffusion(vae, text_encoder, scheduler, transformer)\n\n# Training setup\noptimizer = torch.optim.AdamW(model.denoiser.parameters(), lr=1e-4)\nscaler = GradScaler()  # Mixed precision training [[6]]\n\ncount_parameters(transformer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:26.134289Z","iopub.execute_input":"2025-10-07T15:46:26.134831Z","iopub.status.idle":"2025-10-07T15:46:32.234678Z","shell.execute_reply.started":"2025-10-07T15:46:26.134800Z","shell.execute_reply":"2025-10-07T15:46:32.234045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nfrom kaggle_secrets import UserSecretsClient\nneptune_api = UserSecretsClient().get_secret(\"NEPTUNE_API_TOKEN\")\nneptune_project =UserSecretsClient().get_secret(\"NEPTUNE_PROJECT\")\nbase_model_id='tirthadagr8/LatentDiffusionUNET'\n\nimport neptune\n\nrun=neptune.init_run(\n    project=neptune_project,\n    api_token=neptune_api,\n)\nrun['model']='t2-Custom_Unet_Latent_Diffusion'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:32.235438Z","iopub.execute_input":"2025-10-07T15:46:32.235706Z","iopub.status.idle":"2025-10-07T15:46:32.239528Z","shell.execute_reply.started":"2025-10-07T15:46:32.235687Z","shell.execute_reply":"2025-10-07T15:46:32.238822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom accelerate import Accelerator\nfrom diffusers.training_utils import compute_snr\n\ndef train(\n    model,\n    tokenizer,\n    dataset,\n    batch_size: int = 8,\n    lr: float = 1e-4,\n    num_epochs: int = 5,\n    gradient_accumulation_steps: int = 1,\n    max_grad_norm: float = 1.0,\n    use_xformers: bool = True,\n    min_snr_gamma: float = 5.0,\n):\n    # 1) Accelerator for fp16\n    accelerator = Accelerator(mixed_precision=\"no\",gradient_accumulation_steps=gradient_accumulation_steps)\n\n    # 2) If you have >1 GPU, wrap in DataParallel\n    #    (this must happen *before* you call .to(device) below,\n    #     and *before* accelerate.prepare)\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel\")\n        model = nn.DataParallel(model)\n\n    # 3) DataLoader & optimizer & scheduler as before\n    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4,drop_last=True,\\\n                           collate_fn=lambda b: collate_fn(b, tokenizer=tokenizer))\n    optimizer  = torch.optim.AdamW(model.module.denoiser.parameters() if isinstance(model, nn.DataParallel) else model.denoiser.parameters(), lr=lr)\n    total_steps = len(dataloader) // gradient_accumulation_steps * num_epochs\n    warmup_steps = int(total_steps*0.01)\n    lr_scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n\n    # 4) Prepare everything with Accelerate\n    model, optimizer, dataloader, lr_scheduler = accelerator.prepare(\n        model, optimizer, dataloader, lr_scheduler\n    )\n    unwrapped_model = accelerator.unwrap_model(model)\n    print(f'Training Started for {unwrapped_model.scheduler.config.prediction_type}')\n    iter_k = 1\n    for epoch in range(num_epochs):\n        model.train()\n        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n        for step, batch in enumerate(pbar):\n            images = batch[\"image\"].to(accelerator.device)            \n            input_ids = batch[\"input_ids\"].to(accelerator.device)\n            attn_mask=batch[\"attention_mask\"].to(accelerator.device)\n            timesteps = torch.randint(\n                0, 1000, \n                (images.shape[0],),  # Shape: [4]\n                device='cuda'\n            ).long()\n            # Note: when wrapped in DataParallel your forward signature\n            # still works, because model(images, ...) dispatches to each GPU.\n            with accelerator.accumulate(model):\n                pred_noise, noise, latents = model(images, input_ids, attn_mask, timesteps)\n                if unwrapped_model.scheduler.config.prediction_type == 'epsilon':\n                    target = noise\n                elif unwrapped_model.scheduler.config.prediction_type == 'v_prediction':\n                    target = unwrapped_model.scheduler.get_velocity(latents, noise, timesteps)\n                snr = compute_snr(unwrapped_model.scheduler, timesteps)\n                snr_weights = torch.stack([snr, min_snr_gamma * torch.ones_like(timesteps)], dim=1).min(\n                        dim=1\n                    )[0]\n                if unwrapped_model.scheduler.config.prediction_type == \"epsilon\":\n                    snr_weights = snr_weights / snr\n                elif unwrapped_model.scheduler.config.prediction_type == \"v_prediction\":\n                    snr_weights = snr_weights / (snr + 1)\n                mse_loss_unweighted = F.mse_loss(pred_noise.float(), target.float(), reduction='none')\n                mse_loss_unweighted = mse_loss_unweighted.mean(dim=list(range(1, len(mse_loss_unweighted.shape))))\n                loss = (snr_weights * mse_loss_unweighted).mean()\n                # print('Timesteps:',timesteps)\n                # print('Value:',snr_weights)\n                # print('Shape:',snr_weights.shape)\n                # print('Mean:',snr_weights.mean())\n                # loss = F.mse_loss(pred_noise, noise)\n                accelerator.backward(loss)\n                if accelerator.sync_gradients:\n                    # Get the parameters to clip\n                    params_to_clip = model.module.denoiser.parameters() if isinstance(model, nn.DataParallel) else model.denoiser.parameters()\n                    accelerator.clip_grad_norm_(params_to_clip, max_grad_norm)\n                optimizer.step()\n                lr_scheduler.step()\n                optimizer.zero_grad()\n            # return model\n            run['train/loss'].append(loss.item())\n            run['train/lr'].append(lr_scheduler.get_last_lr()[0])\n            \n            pbar.set_postfix({\"loss\": loss.item()})\n            if iter_k%100==0:\n                # ims=inference('a cat in a hat',model)\n                # ims[0].save(f'img_{iter_k}.png')\n                # run[f'model/output/img_{iter_k}'].upload(f'/kaggle/working/img_{iter_k}.png')\n                if accelerator.is_main_process:\n                    # state_dict = model.module.denoiser.state_dict() if isinstance(model, nn.DataParallel) else model.denoiser.state_dict()\n                    # torch.save(state_dict, f\"dit_epoch.pt\")\n                    model.module.denoiser.save_pretrained('transformer') if isinstance(model, nn.DataParallel) else model.denoiser.save_pretrained('transformer')\n                    \n            # if iter_k>=4000:\n            #     return model\n                \n            iter_k+=1\n\n        # Save the underlying denoiser’s weights\n        if accelerator.is_main_process:\n            state_dict = model.module.denoiser.state_dict() if isinstance(model, nn.DataParallel) else model.denoiser.state_dict()\n            torch.save(state_dict, f\"dit_epoch.pt\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:59.149029Z","iopub.execute_input":"2025-10-07T15:46:59.149759Z","iopub.status.idle":"2025-10-07T15:46:59.161781Z","shell.execute_reply.started":"2025-10-07T15:46:59.149734Z","shell.execute_reply":"2025-10-07T15:46:59.161137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_encoder.save_pretrained('text_encoder')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T16:06:03.631361Z","iopub.execute_input":"2025-10-07T16:06:03.631631Z","iopub.status.idle":"2025-10-07T16:06:04.200020Z","shell.execute_reply.started":"2025-10-07T16:06:03.631611Z","shell.execute_reply":"2025-10-07T16:06:04.199232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6) Start training\ntrained_model = train(\n    model, tokenizer, dataset, batch_size=128, lr=1.25e-5, num_epochs=20, gradient_accumulation_steps=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T15:46:59.429927Z","iopub.execute_input":"2025-10-07T15:46:59.430159Z","iopub.status.idle":"2025-10-07T16:05:51.007745Z","shell.execute_reply.started":"2025-10-07T15:46:59.430142Z","shell.execute_reply":"2025-10-07T16:05:51.006720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_encoder(decoder_input_ids=t['input_ids'].to('cuda'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom PIL import Image\nimport os # Make sure os is imported\n\n# Assuming your Diffusion model, VAE, tokenizer, etc. are already defined as in your code.\n# The 'model' parameter here should be the trained 'Diffusion' instance.\n\ndef generate_image(\n    model, \n    prompt: str,\n    negative_prompt: str = \"\",\n    num_inference_steps: int = 50,\n    guidance_scale: float = 7.5,\n    seed: int = 42,\n    device: str = \"cuda\"\n):\n    \"\"\"\n    Generates an image from a text prompt using the trained DDPM-based model.\n    \"\"\"\n    # --- 0. Setup ---\n    # Unwrap the model if it was prepared with Accelerate or DataParallel\n    if hasattr(model, 'module'):\n        model = model.module\n        \n    # Access the individual components from your Diffusion class\n    vae = model.vae\n    text_encoder = model.text_encoder\n    tokenizer = model.tokenizer\n    scheduler = model.scheduler\n    denoiser = model.denoiser\n    \n    denoiser.eval()\n    vae.eval()\n    text_encoder.eval()\n    \n    height, width = img_size # Using global img_size from your script\n    latent_height, latent_width = height // model.vae_scale_factor, width // model.vae_scale_factor\n\n    generator = torch.Generator(device=device).manual_seed(seed)\n    \n    print(\"--- 1. Encoding prompts ---\")\n    # --- 1. Encode text prompts (positive and negative) ---\n    prompts = [\"\", prompt]\n    \n    # Tokenize\n    text_inputs = tokenizer(\n        prompts, \n        padding=\"max_length\", \n        max_length=tokenizer.model_max_length, \n        truncation=True, \n        return_tensors=\"pt\"\n    )\n    input_ids = text_inputs.input_ids.to(device)\n    attention_mask = text_inputs.attention_mask.to(device)\n\n    # Get text embeddings\n    with torch.no_grad():\n        text_embeddings = text_encoder(input_ids, attention_mask=attention_mask).last_hidden_state\n\n    # For classifier-free guidance, we need two sets of embeddings:\n    # unconditional (for negative prompt) and conditional (for positive prompt)\n    uncond_embeddings, cond_embeddings = text_embeddings.chunk(2)\n    # The denoiser expects the embeddings to be concatenated\n    text_embeddings = torch.cat([uncond_embeddings, cond_embeddings])\n    \n    # We also need the attention mask for cross-attention\n    uncond_mask, cond_mask = attention_mask.chunk(2)\n    attention_mask = torch.cat([uncond_mask, cond_mask])\n\n\n    print(\"--- 2. Preparing latent space ---\")\n    # --- 2. Create initial random noise (latents) ---\n    latents = torch.randn(\n        (1, denoiser.config.in_channels, latent_height, latent_width),\n        generator=generator,\n        device=device,\n        dtype=text_embeddings.dtype # Use fp16 if model is in fp16\n    )\n\n    # --- 3. Denoising Loop ---\n    scheduler.set_timesteps(num_inference_steps)\n    \n    # Scale the initial noise by the scheduler's sigma value\n    latents = latents * scheduler.init_noise_sigma\n\n    print(\"--- 3. Starting denoising loop ---\")\n    for t in tqdm(scheduler.timesteps):\n        # We need to repeat the latents for both conditional and unconditional passes\n        latent_model_input = torch.cat([latents] * 2)\n        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n        t_batch = t.repeat(latent_model_input.shape[0])\n        # Predict the noise\n        with torch.no_grad():\n            noise_pred = denoiser(\n                latent_model_input,\n                timestep=t_batch.to(device),\n                encoder_hidden_states=text_embeddings,\n                encoder_attention_mask=attention_mask # Use the correct parameter name!\n            ).sample\n\n        # Perform classifier-free guidance\n        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n        # Denoise the latents by one step\n        latents = scheduler.step(noise_pred, t, latents).prev_sample\n\n    print(\"--- 4. Decoding latents to image ---\")\n    # --- 4. Decode the latents into an image ---\n    # Un-scale the latents\n    latents = 1 / vae.config.scaling_factor * latents\n    with torch.no_grad():\n        image = vae.decode(latents).sample\n\n    # --- 5. Post-process the image ---\n    image = (image / 2 + 0.5).clamp(0, 1)\n    # Convert from PyTorch tensor (B, C, H, W) to PIL image (H, W, C)\n    image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n    image = (image * 255).round().astype(\"uint8\")\n    pil_image = Image.fromarray(image[0])\n    \n    return pil_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device='cuda:1'\nvae = AutoencoderKL.from_pretrained(vae_model).to(device)\ntext_encoder = BertModel.from_pretrained(text_encoder_name).to(device)\ntokenizer = BertTokenizer.from_pretrained(text_encoder_name)\ntokenizer.model_max_length=model_max_length\nscheduler = DDPMScheduler(**ddpm_config)\ntransformer = Transformer2DModel(**conf)#.to('cuda')\n\n# Freeze VAE and text encoder [[7]]\nvae.requires_grad_(False)\ntext_encoder.requires_grad_(False)\n\n# Enable gradient checkpointing for memory efficiency [[6]]\ntransformer.enable_gradient_checkpointing()\nif os.path.exists(ckpt_path):\n    transformer.load_state_dict(torch.load(ckpt_path,map_location=device))\n    print('*** Loaded Transformer weights ***')\n# Enable xFormers for attention optimization [[6]]\ntry:\n    import xformers\n    transformer.enable_xformers_memory_efficient_attention()\nexcept ImportError:\n    print(\"xFormers not found; proceeding without.\")\n\n# Create combined model\nmodel = Diffusion(vae, text_encoder, tokenizer, scheduler, transformer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.denoiser.load_state_dict(torch.load(\"/kaggle/working/dit_epoch.pt\", map_location=device))\n\n# Make sure the model is on the correct device and in evaluation mode\nmodel.to(device)\nmodel.eval()\n\n# --- Call the generation function ---\nprompt=\"1girl, arm tattoo, armpits, arms behind head, arms up, bandages, bangs, blonde hair, blush, breasts, chest tattoo, choker, cleavage, genshin impact, gloves, hair between eyes, hair ornament, japanese clothes, kimono, large breasts, long hair, looking at viewer, orange kimono, ponytail, red choker, rope, sarashi, short ponytail, solo, sweat, tattoo, wet, yamamoto (ymmt is sexy), yellow eyes, yoimiya (genshin impact)\"\nprompt=''\nnegative_prompt = prompt\n\ngenerated_image = generate_image(\n    model=model,\n    prompt=prompt,\n    negative_prompt=negative_prompt,\n    num_inference_steps=50,\n    guidance_scale=7.5,\n    seed=12345,\n    device=device\n)\n\n# --- Save or display the image ---\ngenerated_image.save(\"generated_lion.png\")\nprint(\"Image saved as generated_lion.png\")\nplt.imshow(Image.open('/kaggle/working/generated_lion.png'))\nplt.show()\n# If you're in a Jupyter notebook, you can display it directly\n# display(generated_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run['train/image'].upload('/kaggle/working/generated_lion.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms.functional import to_pil_image\n# prompt = \"Two young guys with shaggy hair look at their hands while hanging out in the yard .\"\nguidance_scale=0\nfor i in tqdm(range(21)):\n    images = generate_image(\n    model=model,\n    prompt=prompt,\n    negative_prompt=negative_prompt,\n    num_inference_steps=50,\n    guidance_scale=guidance_scale,\n    seed=12345,\n    device=device\n)\n    pil_img = images#to_pil_image(images[0].cpu())\n    # pil_img.save(f\"C:/Users/tirth/Desktop/sample_images/sample_{guidance_scale}.png\")\n    plt.imshow(pil_img)\n    plt.show()\n    guidance_scale+=0.5","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}